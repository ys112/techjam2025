{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155090e0",
   "metadata": {},
   "source": [
    "# üèÜ TechJam 2025: Review Quality Assessment System\n",
    "\n",
    "## üéØ Challenge: ML for Trustworthy Location Reviews\n",
    "\n",
    "This notebook will guide you through building a system to detect policy violations in Google location reviews:\n",
    "- üö´ **Advertisements**: Reviews containing promotional content\n",
    "- üö´ **Irrelevant Content**: Reviews not related to the location\n",
    "- üö´ **Fake Rants**: Complaints from users who never visited\n",
    "\n",
    "**Today's Goal (Day 1)**: Set up environment, explore data, and build basic understanding\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807423ad",
   "metadata": {},
   "source": [
    "## üìö Step 1: Import Required Libraries\n",
    "\n",
    "Let's start by importing all the libraries we'll need for data processing, ML models, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e838ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "# Uncomment the lines below if you need to install packages\n",
    "\n",
    "# !pip install pandas numpy matplotlib seaborn\n",
    "# !pip install transformers torch\n",
    "# !pip install huggingface_hub\n",
    "# !pip install scikit-learn\n",
    "# !pip install streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d305d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML and NLP libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# Hugging Face transformers\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import torch\n",
    "    print(\"‚úÖ Transformers library loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Transformers not installed. Please run: pip install transformers torch\")\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6062528",
   "metadata": {},
   "source": [
    "## üìä Step 2: Data Loading and Initial Exploration\n",
    "\n",
    "First, let's load the Google Reviews dataset and understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_reviews_data(max_reviews=5000):\n",
    "    \"\"\"\n",
    "    Load Google Reviews dataset from the compressed JSON files\n",
    "    Joins reviews with business metadata\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    \n",
    "    print(\"üì• Loading Google Reviews dataset...\")\n",
    "    \n",
    "    # Load reviews data\n",
    "    reviews_data = []\n",
    "    with gzip.open('review_South_Dakota.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= max_reviews:\n",
    "                break\n",
    "            review = json.loads(line)\n",
    "            # Only include reviews that have text content\n",
    "            if review.get('text'):\n",
    "                reviews_data.append(review)\n",
    "    \n",
    "    df_reviews = pd.DataFrame(reviews_data)\n",
    "    \n",
    "    # Load business metadata\n",
    "    meta_data = []\n",
    "    with gzip.open('meta_South_Dakota.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            meta_data.append(json.loads(line))\n",
    "    \n",
    "    df_meta = pd.DataFrame(meta_data)\n",
    "    \n",
    "    # Select relevant metadata columns\n",
    "    meta_cols = ['gmap_id', 'name', 'category', 'avg_rating', 'num_of_reviews', \n",
    "                 'latitude', 'longitude', 'address']\n",
    "    meta_cols = [col for col in meta_cols if col in df_meta.columns]\n",
    "    df_meta_clean = df_meta[meta_cols].drop_duplicates(subset=['gmap_id'])\n",
    "    \n",
    "    # Join reviews with business metadata\n",
    "    df_combined = df_reviews.merge(df_meta_clean, on='gmap_id', how='left', suffixes=('_user', '_business'))\n",
    "    \n",
    "    # Rename columns to match notebook expectations\n",
    "    df_combined = df_combined.rename(columns={\n",
    "        'text': 'review_text',\n",
    "        'name_business': 'business_name',\n",
    "        'name_user': 'user_name'\n",
    "    })\n",
    "    \n",
    "    # Handle missing business names\n",
    "    df_combined['business_name'] = df_combined['business_name'].fillna('Unknown Business')\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df_combined)} reviews with text content\")\n",
    "    return df_combined\n",
    "\n",
    "def load_sample_data():\n",
    "    \"\"\"\n",
    "    Fallback function with sample data if main loading fails\n",
    "    \"\"\"\n",
    "    sample_reviews = [\n",
    "        # Normal reviews\n",
    "        {\"review_text\": \"Great food and excellent service. The pasta was delicious and the staff was very friendly. Highly recommend!\", \"rating\": 5, \"business_name\": \"Mario's Restaurant\"},\n",
    "        {\"review_text\": \"Average experience. Food was okay but service was slow. Not bad but not great either.\", \"rating\": 3, \"business_name\": \"Central Cafe\"},\n",
    "        {\"review_text\": \"Terrible experience. Food was cold and the waiter was rude. Will not return.\", \"rating\": 1, \"business_name\": \"Downtown Diner\"},\n",
    "        # Advertisement examples\n",
    "        {\"review_text\": \"Amazing pizza! Visit our website www.pizzadeals.com for 50% off coupons and special offers!\", \"rating\": 5, \"business_name\": \"Tony's Pizza\"},\n",
    "        {\"review_text\": \"Great burgers! Call us at 555-BURGER for catering services and party packages!\", \"rating\": 5, \"business_name\": \"Burger Palace\"},\n",
    "        {\"review_text\": \"Delicious food! Check out our new location on Main Street. Grand opening specials available!\", \"rating\": 5, \"business_name\": \"Fresh Bites\"},\n",
    "        # Irrelevant content examples\n",
    "        {\"review_text\": \"I love my new smartphone camera! Anyway, this restaurant has okay food I guess.\", \"rating\": 3, \"business_name\": \"City Grill\"},\n",
    "        {\"review_text\": \"Traffic was terrible today because of construction. Politics are crazy these days. Oh, the coffee was fine.\", \"rating\": 3, \"business_name\": \"Corner Coffee\"},\n",
    "        {\"review_text\": \"My car broke down on the way here, what a terrible day. The weather is also awful. Food was decent though.\", \"rating\": 2, \"business_name\": \"Highway Diner\"},\n",
    "        # Fake rant examples\n",
    "        {\"review_text\": \"Never been here but I heard from my neighbor that it's absolutely terrible. Probably overpriced too.\", \"rating\": 1, \"business_name\": \"Elite Restaurant\"},\n",
    "        {\"review_text\": \"I hate these fancy restaurants, they're all scams. Never visited but I'm sure it's pretentious.\", \"rating\": 1, \"business_name\": \"Fine Dining Co\"},\n",
    "        {\"review_text\": \"Looks dirty from the outside, probably awful inside too. Won't waste my time going there.\", \"rating\": 1, \"business_name\": \"Street Food Truck\"}\n",
    "    ]\n",
    "    return pd.DataFrame(sample_reviews)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = load_google_reviews_data(max_reviews=5000)\n",
    "    print(\"üéâ Successfully loaded real Google Reviews dataset!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to load real data ({e}), using sample data\")\n",
    "    df = load_sample_data()\n",
    "\n",
    "print(f\"\\nüìä Dataset loaded with {len(df)} reviews\")\n",
    "print(f\"üìã Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nüìù First 3 reviews:\")\n",
    "df[['review_text', 'rating', 'business_name']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "def explore_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic exploration of the review dataset\n",
    "    \"\"\"\n",
    "    print(\"üîç BASIC DATA EXPLORATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Dataset info\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Text statistics\n",
    "    df['review_length'] = df['review_text'].str.len()\n",
    "    df['word_count'] = df['review_text'].str.split().str.len()\n",
    "    \n",
    "    print(f\"\\nüìè Review Length Statistics:\")\n",
    "    print(f\"  Average length: {df['review_length'].mean():.1f} characters\")\n",
    "    print(f\"  Average words: {df['word_count'].mean():.1f} words\")\n",
    "    print(f\"  Shortest review: {df['review_length'].min()} characters\")\n",
    "    print(f\"  Longest review: {df['review_length'].max()} characters\")\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(f\"\\n‚≠ê Rating Distribution:\")\n",
    "    print(df['rating'].value_counts().sort_index())\n",
    "    \n",
    "    # Business statistics (if real data loaded)\n",
    "    if 'business_name' in df.columns and len(df['business_name'].unique()) > 20:\n",
    "        print(f\"\\nüè¢ Business Statistics:\")\n",
    "        print(f\"  Unique businesses: {df['business_name'].nunique()}\")\n",
    "        print(f\"  Top 5 most reviewed businesses:\")\n",
    "        top_businesses = df['business_name'].value_counts().head(5)\n",
    "        for business, count in top_businesses.items():\n",
    "            print(f\"    {business}: {count} reviews\")\n",
    "        \n",
    "        # Category information (if available)\n",
    "        if 'category' in df.columns:\n",
    "            non_null_categories = df['category'].dropna()\n",
    "            if len(non_null_categories) > 0:\n",
    "                print(f\"\\nüè∑Ô∏è Business Categories (sample):\")\n",
    "                # Show a few example categories\n",
    "                for i, cat in enumerate(non_null_categories.head(3)):\n",
    "                    if isinstance(cat, list) and len(cat) > 0:\n",
    "                        print(f\"    {cat}\")\n",
    "                    elif isinstance(cat, str):\n",
    "                        print(f\"    {cat}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = explore_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Review length distribution\n",
    "axes[0, 0].hist(df['review_length'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Distribution of Review Length (Characters)')\n",
    "axes[0, 0].set_xlabel('Characters')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Word count distribution\n",
    "axes[0, 1].hist(df['word_count'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('Distribution of Word Count')\n",
    "axes[0, 1].set_xlabel('Words')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Rating distribution\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "axes[1, 0].bar(rating_counts.index, rating_counts.values, alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Distribution of Ratings')\n",
    "axes[1, 0].set_xlabel('Rating')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# Review length vs rating scatter\n",
    "axes[1, 1].scatter(df['rating'], df['review_length'], alpha=0.6, color='purple')\n",
    "axes[1, 1].set_title('Review Length vs Rating')\n",
    "axes[1, 1].set_xlabel('Rating')\n",
    "axes[1, 1].set_ylabel('Review Length (Characters)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Data visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60371037",
   "metadata": {},
   "source": [
    "## üîß Step 3: Feature Engineering\n",
    "\n",
    "Let's extract useful features that can help identify policy violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d179ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"\n",
    "    Extract features that might indicate policy violations\n",
    "    \"\"\"\n",
    "    print(\"üîß EXTRACTING FEATURES FOR VIOLATION DETECTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic text features\n",
    "    df['review_length'] = df['review_text'].str.len()\n",
    "    df['word_count'] = df['review_text'].str.split().str.len()\n",
    "    df['exclamation_count'] = df['review_text'].str.count('!')\n",
    "    df['question_count'] = df['review_text'].str.count('\\?')\n",
    "    \n",
    "    # Capitalization features (potential indicators of spam/rants)\n",
    "    df['caps_ratio'] = df['review_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "    df['excessive_caps'] = df['caps_ratio'] > 0.3\n",
    "    \n",
    "    # Advertisement indicators\n",
    "    df['has_url'] = df['review_text'].str.contains(r'http[s]?://|www\\.', regex=True, na=False)\n",
    "    df['has_phone'] = df['review_text'].str.contains(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b|call|phone', regex=True, na=False, case=False)\n",
    "    df['has_promo_words'] = df['review_text'].str.contains(r'discount|deal|promo|sale|coupon|special offer|visit|website', regex=True, na=False, case=False)\n",
    "    \n",
    "    # Irrelevant content indicators\n",
    "    df['mentions_unrelated'] = df['review_text'].str.contains(r'my phone|my car|politics|weather|traffic|news|government', regex=True, na=False, case=False)\n",
    "    \n",
    "    # Fake rant indicators\n",
    "    df['never_visited'] = df['review_text'].str.contains(r'never been|never visited|heard it|looks like|probably|i hate these|all these places', regex=True, na=False, case=False)\n",
    "    \n",
    "    # Length-based features\n",
    "    df['very_short'] = df['word_count'] < 5\n",
    "    df['very_long'] = df['word_count'] > 200\n",
    "    \n",
    "    print(f\"‚úÖ Extracted {len([col for col in df.columns if col not in ['review_text', 'rating', 'business_name']])} features\")\n",
    "    \n",
    "    # Show feature summary\n",
    "    feature_cols = ['has_url', 'has_phone', 'has_promo_words', 'mentions_unrelated', 'never_visited', 'excessive_caps']\n",
    "    print(\"\\nüìä Feature Summary:\")\n",
    "    for col in feature_cols:\n",
    "        count = df[col].sum()\n",
    "        print(f\"  {col}: {count} reviews ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = extract_features(df)\n",
    "print(\"\\nüìã Sample of extracted features:\")\n",
    "df[['review_text', 'has_url', 'has_promo_words', 'mentions_unrelated', 'never_visited']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a97eb",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 4: Pseudo-Labeling (Create Ground Truth for Demo)\n",
    "\n",
    "Since we're using real data, we'll create pseudo-labels using keyword patterns for demonstration purposes. In production, you would manually label a subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd89c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pseudo_labels(df):\n",
    "    \"\"\"\n",
    "    Create pseudo-labels based on keyword detection for demonstration\n",
    "    In a real scenario, you would manually label a subset of data\n",
    "    \"\"\"\n",
    "    print(\"üè∑Ô∏è CREATING PSEUDO-LABELS FOR DEMONSTRATION\")\n",
    "    print(\"=\" * 45)\n",
    "    print(\"‚ÑπÔ∏è  Note: In production, you should manually label a subset of data\")\n",
    "    \n",
    "    # Initialize all labels as 0 (no violation)\n",
    "    df['is_advertisement'] = 0\n",
    "    df['is_irrelevant'] = 0\n",
    "    df['is_fake_rant'] = 0\n",
    "    \n",
    "    # Create pseudo-labels based on strong keyword indicators\n",
    "    # These are simplified heuristics for demonstration purposes\n",
    "    \n",
    "    # Advertisement indicators\n",
    "    ad_patterns = r'(visit our website|call us at|discount|promotion|special offer|visit www|check out our)'\n",
    "    df.loc[df['review_text'].str.contains(ad_patterns, case=False, na=False), 'is_advertisement'] = 1\n",
    "    \n",
    "    # Irrelevant content indicators\n",
    "    irrelevant_patterns = r'(my phone|my car|politics|the weather|traffic was|construction|my personal life)'\n",
    "    df.loc[df['review_text'].str.contains(irrelevant_patterns, case=False, na=False), 'is_irrelevant'] = 1\n",
    "    \n",
    "    # Fake rant indicators\n",
    "    fake_rant_patterns = r'(never been here|heard it was|looks terrible|probably bad|i hate these places)'\n",
    "    df.loc[df['review_text'].str.contains(fake_rant_patterns, case=False, na=False), 'is_fake_rant'] = 1\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"üìä Pseudo-Label Summary:\")\n",
    "    print(f\"  Advertisements: {df['is_advertisement'].sum()}/{len(df)} ({df['is_advertisement'].sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Irrelevant: {df['is_irrelevant'].sum()}/{len(df)} ({df['is_irrelevant'].sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Fake Rants: {df['is_fake_rant'].sum()}/{len(df)} ({df['is_fake_rant'].sum()/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_pseudo_labels(df)\n",
    "print(\"\\n‚úÖ Pseudo-labels created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b14dcc",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: Simple Rule-Based Classifier (Baseline)\n",
    "\n",
    "Let's start with a simple rule-based approach as our baseline before moving to ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91969d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRuleBasedClassifier:\n",
    "    \"\"\"\n",
    "    Simple rule-based classifier for policy violation detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define keywords for each violation type\n",
    "        self.ad_keywords = [\n",
    "            'visit', 'website', 'www', 'http', 'call', 'phone', 'discount',\n",
    "            'deal', 'promo', 'sale', 'coupon', 'special offer'\n",
    "        ]\n",
    "        \n",
    "        self.irrelevant_keywords = [\n",
    "            'my phone', 'my car', 'politics', 'weather', 'traffic',\n",
    "            'my day', 'my life', 'news', 'government'\n",
    "        ]\n",
    "        \n",
    "        self.fake_rant_keywords = [\n",
    "            'never been', 'heard it', 'looks like', 'probably',\n",
    "            'i hate these', 'all these places', 'never visited'\n",
    "        ]\n",
    "    \n",
    "    def classify_advertisement(self, text):\n",
    "        \"\"\"Check if review contains advertisement\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.ad_keywords)\n",
    "    \n",
    "    def classify_irrelevant(self, text):\n",
    "        \"\"\"Check if review contains irrelevant content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.irrelevant_keywords)\n",
    "    \n",
    "    def classify_fake_rant(self, text):\n",
    "        \"\"\"Check if review is a fake rant\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.fake_rant_keywords)\n",
    "    \n",
    "    def classify_review(self, text):\n",
    "        \"\"\"Classify a single review for all violation types\"\"\"\n",
    "        return {\n",
    "            'advertisement': self.classify_advertisement(text),\n",
    "            'irrelevant': self.classify_irrelevant(text),\n",
    "            'fake_rant': self.classify_fake_rant(text)\n",
    "        }\n",
    "    \n",
    "    def classify_batch(self, texts):\n",
    "        \"\"\"Classify multiple reviews\"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            results.append(self.classify_review(text))\n",
    "        return results\n",
    "\n",
    "# Test the rule-based classifier\n",
    "print(\"ü§ñ TESTING RULE-BASED CLASSIFIER\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "classifier = SimpleRuleBasedClassifier()\n",
    "\n",
    "# Get predictions\n",
    "reviews = df['review_text'].tolist()\n",
    "predictions = classifier.classify_batch(reviews)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df['pred_advertisement'] = [pred['advertisement'] for pred in predictions]\n",
    "df['pred_irrelevant'] = [pred['irrelevant'] for pred in predictions]\n",
    "df['pred_fake_rant'] = [pred['fake_rant'] for pred in predictions]\n",
    "\n",
    "print(\"‚úÖ Rule-based classification complete!\")\n",
    "print(f\"\\nüìä Prediction Summary:\")\n",
    "print(f\"  Predicted Advertisements: {df['pred_advertisement'].sum()}\")\n",
    "print(f\"  Predicted Irrelevant: {df['pred_irrelevant'].sum()}\")\n",
    "print(f\"  Predicted Fake Rants: {df['pred_fake_rant'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d05ff",
   "metadata": {},
   "source": [
    "## üìä Step 6: Evaluation and Metrics\n",
    "\n",
    "Let's evaluate our rule-based classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(df, violation_type):\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance for a specific violation type\n",
    "    \"\"\"\n",
    "    true_col = f'is_{violation_type}'\n",
    "    pred_col = f'pred_{violation_type}'\n",
    "    \n",
    "    y_true = df[true_col].tolist()\n",
    "    y_pred = df[pred_col].tolist()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    accuracy = sum(t == p for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(df, violation_type):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for a violation type\n",
    "    \"\"\"\n",
    "    true_col = f'is_{violation_type}'\n",
    "    pred_col = f'pred_{violation_type}'\n",
    "    \n",
    "    y_true = df[true_col].tolist()\n",
    "    y_pred = df[pred_col].tolist()\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=['No Violation', 'Violation'],\n",
    "               yticklabels=['No Violation', 'Violation'])\n",
    "    plt.title(f'Confusion Matrix - {violation_type.title()} Detection')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate all violation types\n",
    "print(\"üìä RULE-BASED CLASSIFIER EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "violation_types = ['advertisement', 'irrelevant', 'fake_rant']\n",
    "results = {}\n",
    "\n",
    "for vtype in violation_types:\n",
    "    metrics = evaluate_classifier(df, vtype)\n",
    "    results[vtype] = metrics\n",
    "    \n",
    "    print(f\"\\nüéØ {vtype.upper()} DETECTION:\")\n",
    "    print(f\"  Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.3f}\")\n",
    "    print(f\"  F1-Score:  {metrics['f1_score']:.3f}\")\n",
    "    print(f\"  Accuracy:  {metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(df, vtype)\n",
    "\n",
    "# Overall average F1-score\n",
    "avg_f1 = np.mean([results[vtype]['f1_score'] for vtype in violation_types])\n",
    "print(f\"\\nüèÜ OVERALL AVERAGE F1-SCORE: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcaa4a",
   "metadata": {},
   "source": [
    "## üîÆ Step 7: Prepare for ML Models (Next Session)\n",
    "\n",
    "Let's set up the foundation for using Hugging Face models in our next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc771731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_huggingface_models():\n",
    "    \"\"\"\n",
    "    Test Hugging Face model loading for next session\n",
    "    \"\"\"\n",
    "    print(\"üîÆ PREPARING FOR ML MODELS (DAY 2)\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    try:\n",
    "        # Test loading a simple classification model\n",
    "        print(\"Testing model loading...\")\n",
    "        classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            device=-1  # Use CPU\n",
    "        )\n",
    "        \n",
    "        # Test on a sample review\n",
    "        test_review = \"Great food and excellent service!\"\n",
    "        result = classifier(test_review)\n",
    "        \n",
    "        print(f\"‚úÖ Model loading successful!\")\n",
    "        print(f\"Test result: {result}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model loading failed: {e}\")\n",
    "        print(\"This is okay - we'll set this up properly in Day 2\")\n",
    "        return False\n",
    "\n",
    "model_ready = setup_huggingface_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bac5c1",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save Progress and Plan Next Steps\n",
    "\n",
    "Let's save our work and prepare for tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for next session\n",
    "df.to_csv('processed_reviews_day1.csv', index=False)\n",
    "print(\"üíæ Data saved to 'processed_reviews_day1.csv'\")\n",
    "\n",
    "# Save results summary\n",
    "summary = {\n",
    "    'day': 1,\n",
    "    'date': '2025-08-25',\n",
    "    'dataset_size': len(df),\n",
    "    'features_extracted': len([col for col in df.columns if col.startswith(('has_', 'is_', 'pred_'))]),\n",
    "    'baseline_results': results,\n",
    "    'avg_f1_score': avg_f1,\n",
    "    'next_steps': [\n",
    "        'Implement Hugging Face models',\n",
    "        'Improve prompt engineering',\n",
    "        'Test on larger dataset',\n",
    "        'Create ensemble approach'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('day1_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"üìÑ Summary saved to 'day1_summary.json'\")\n",
    "\n",
    "print(\"\\nüéâ DAY 1 COMPLETE!\")\n",
    "print(\"=\" * 20)\n",
    "print(\"‚úÖ Environment set up\")\n",
    "print(\"‚úÖ Data loaded and explored\")\n",
    "print(\"‚úÖ Features extracted\")\n",
    "print(\"‚úÖ Baseline classifier implemented\")\n",
    "print(\"‚úÖ Evaluation metrics calculated\")\n",
    "print(f\"‚úÖ Baseline F1-score: {avg_f1:.3f}\")\n",
    "\n",
    "print(\"\\nüìÖ TOMORROW'S PLAN (Day 2):\")\n",
    "print(\"üéØ Implement Hugging Face models\")\n",
    "print(\"üéØ Create smart prompts for LLMs\")\n",
    "print(\"üéØ Test and improve accuracy\")\n",
    "print(\"üéØ Prepare for demo creation\")\n",
    "\n",
    "print(\"\\nüèÜ Great job! You're on track to win this hackathon! üèÜ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
