{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155090e0",
   "metadata": {},
   "source": [
    "# üèÜ TechJam 2025: Review Quality Assessment System\n",
    "\n",
    "## üéØ Challenge: ML for Trustworthy Location Reviews\n",
    "\n",
    "This notebook will guide you through building a system to detect policy violations in Google location reviews:\n",
    "- üö´ **Advertisements**: Reviews containing promotional content\n",
    "- üö´ **Irrelevant Content**: Reviews not related to the location\n",
    "- üö´ **Fake Rants**: Complaints from users who never visited\n",
    "\n",
    "**Today's Goal (Day 1)**: Set up environment, explore data, and build basic understanding\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807423ad",
   "metadata": {},
   "source": [
    "## üìö Step 1: Import Required Libraries\n",
    "\n",
    "Let's start by importing all the libraries we'll need for data processing, ML models, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e838ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this if packages are not installed)\n",
    "# Uncomment the lines below if you need to install packages\n",
    "\n",
    "# !pip install pandas numpy matplotlib seaborn\n",
    "# !pip install transformers torch\n",
    "# !pip install huggingface_hub\n",
    "# !pip install scikit-learn\n",
    "# !pip install streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d305d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML and NLP libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "# Hugging Face transformers\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import torch\n",
    "    print(\"‚úÖ Transformers library loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Transformers not installed. Please run: pip install transformers torch\")\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6062528",
   "metadata": {},
   "source": [
    "## üìä Step 2: Data Loading and Initial Exploration\n",
    "\n",
    "First, let's load the Google Reviews dataset and understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data():\n",
    "    \"\"\"\n",
    "    Create sample data for testing if you don't have the dataset yet.\n",
    "    Replace this with actual data loading when you get the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample reviews with different violation types\n",
    "    sample_reviews = [\n",
    "        # Normal reviews\n",
    "        {\"review_text\": \"Great food and excellent service. The pasta was delicious and the staff was very friendly. Highly recommend!\", \"rating\": 5, \"business_name\": \"Mario's Restaurant\"},\n",
    "        {\"review_text\": \"Average experience. Food was okay but service was slow. Not bad but not great either.\", \"rating\": 3, \"business_name\": \"Central Cafe\"},\n",
    "        {\"review_text\": \"Terrible experience. Food was cold and the waiter was rude. Will not return.\", \"rating\": 1, \"business_name\": \"Downtown Diner\"},\n",
    "        \n",
    "        # Advertisement examples\n",
    "        {\"review_text\": \"Amazing pizza! Visit our website www.pizzadeals.com for 50% off coupons and special offers!\", \"rating\": 5, \"business_name\": \"Tony's Pizza\"},\n",
    "        {\"review_text\": \"Great burgers! Call us at 555-BURGER for catering services and party packages!\", \"rating\": 5, \"business_name\": \"Burger Palace\"},\n",
    "        {\"review_text\": \"Delicious food! Check out our new location on Main Street. Grand opening specials available!\", \"rating\": 5, \"business_name\": \"Fresh Bites\"},\n",
    "        \n",
    "        # Irrelevant content examples\n",
    "        {\"review_text\": \"I love my new smartphone camera! Anyway, this restaurant has okay food I guess.\", \"rating\": 3, \"business_name\": \"City Grill\"},\n",
    "        {\"review_text\": \"Traffic was terrible today because of construction. Politics are crazy these days. Oh, the coffee was fine.\", \"rating\": 3, \"business_name\": \"Corner Coffee\"},\n",
    "        {\"review_text\": \"My car broke down on the way here, what a terrible day. The weather is also awful. Food was decent though.\", \"rating\": 2, \"business_name\": \"Highway Diner\"},\n",
    "        \n",
    "        # Fake rant examples\n",
    "        {\"review_text\": \"Never been here but I heard from my neighbor that it's absolutely terrible. Probably overpriced too.\", \"rating\": 1, \"business_name\": \"Elite Restaurant\"},\n",
    "        {\"review_text\": \"I hate these fancy restaurants, they're all scams. Never visited but I'm sure it's pretentious.\", \"rating\": 1, \"business_name\": \"Fine Dining Co\"},\n",
    "        {\"review_text\": \"Looks dirty from the outside, probably awful inside too. Won't waste my time going there.\", \"rating\": 1, \"business_name\": \"Street Food Truck\"}\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(sample_reviews)\n",
    "\n",
    "# Load data\n",
    "# TODO: Replace this with actual dataset loading\n",
    "# df = pd.read_csv('path_to_google_reviews_dataset.csv')\n",
    "\n",
    "# For now, use sample data\n",
    "df = load_sample_data()\n",
    "\n",
    "print(f\"üìä Dataset loaded with {len(df)} reviews\")\n",
    "print(f\"üìã Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nüìù First 3 reviews:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "def explore_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic exploration of the review dataset\n",
    "    \"\"\"\n",
    "    print(\"üîç BASIC DATA EXPLORATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Dataset info\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Text statistics\n",
    "    df['review_length'] = df['review_text'].str.len()\n",
    "    df['word_count'] = df['review_text'].str.split().str.len()\n",
    "    \n",
    "    print(f\"\\nüìè Review Length Statistics:\")\n",
    "    print(f\"  Average length: {df['review_length'].mean():.1f} characters\")\n",
    "    print(f\"  Average words: {df['word_count'].mean():.1f} words\")\n",
    "    print(f\"  Shortest review: {df['review_length'].min()} characters\")\n",
    "    print(f\"  Longest review: {df['review_length'].max()} characters\")\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(f\"\\n‚≠ê Rating Distribution:\")\n",
    "    print(df['rating'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = explore_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Review length distribution\n",
    "axes[0, 0].hist(df['review_length'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Distribution of Review Length (Characters)')\n",
    "axes[0, 0].set_xlabel('Characters')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Word count distribution\n",
    "axes[0, 1].hist(df['word_count'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('Distribution of Word Count')\n",
    "axes[0, 1].set_xlabel('Words')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Rating distribution\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "axes[1, 0].bar(rating_counts.index, rating_counts.values, alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Distribution of Ratings')\n",
    "axes[1, 0].set_xlabel('Rating')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# Review length vs rating scatter\n",
    "axes[1, 1].scatter(df['rating'], df['review_length'], alpha=0.6, color='purple')\n",
    "axes[1, 1].set_title('Review Length vs Rating')\n",
    "axes[1, 1].set_xlabel('Rating')\n",
    "axes[1, 1].set_ylabel('Review Length (Characters)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Data visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60371037",
   "metadata": {},
   "source": [
    "## üîß Step 3: Feature Engineering\n",
    "\n",
    "Let's extract useful features that can help identify policy violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d179ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"\n",
    "    Extract features that might indicate policy violations\n",
    "    \"\"\"\n",
    "    print(\"üîß EXTRACTING FEATURES FOR VIOLATION DETECTION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic text features\n",
    "    df['review_length'] = df['review_text'].str.len()\n",
    "    df['word_count'] = df['review_text'].str.split().str.len()\n",
    "    df['exclamation_count'] = df['review_text'].str.count('!')\n",
    "    df['question_count'] = df['review_text'].str.count('?')  # Fixed: removed invalid escape sequence\n",
    "    \n",
    "    # Capitalization features (potential indicators of spam/rants)\n",
    "    df['caps_ratio'] = df['review_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "    df['excessive_caps'] = df['caps_ratio'] > 0.3\n",
    "    \n",
    "    # Contact information detection (advertisements)\n",
    "    df['has_url'] = df['review_text'].str.contains(r'www\\.|http|\\.com', case=False, na=False)\n",
    "    df['has_phone'] = df['review_text'].str.contains(r'\\d{3}[-.]?\\d{3}[-.]?\\d{4}', na=False)\n",
    "    df['has_email'] = df['review_text'].str.contains(r'@[\\w\\.-]+\\.\\w+', na=False)\n",
    "    \n",
    "    # Promotional language (advertisements)\n",
    "    promotional_keywords = ['discount', 'deal', 'promo', 'sale', 'offer', 'coupon', 'special', 'visit our', 'check out']\n",
    "    df['promotional_words'] = df['review_text'].apply(\n",
    "        lambda x: sum(1 for word in promotional_keywords if word.lower() in x.lower())\n",
    "    )\n",
    "    \n",
    "    # Irrelevant content indicators\n",
    "    irrelevant_keywords = ['politics', 'weather', 'my phone', 'my car', 'personal life', 'coronavirus']\n",
    "    df['irrelevant_words'] = df['review_text'].apply(\n",
    "        lambda x: sum(1 for word in irrelevant_keywords if word.lower() in x.lower())\n",
    "    )\n",
    "    \n",
    "    # Fake rant indicators\n",
    "    fake_rant_keywords = ['never been', 'never visited', 'heard it', 'probably', 'i bet', 'sounds like']\n",
    "    df['fake_rant_words'] = df['review_text'].apply(\n",
    "        lambda x: sum(1 for phrase in fake_rant_keywords if phrase.lower() in x.lower())\n",
    "    )\n",
    "    \n",
    "    # Business context keywords (legitimate reviews should have these)\n",
    "    business_keywords = ['service', 'staff', 'food', 'place', 'experience', 'visit', 'restaurant', 'store']\n",
    "    df['business_words'] = df['review_text'].apply(\n",
    "        lambda x: sum(1 for word in business_keywords if word.lower() in x.lower())\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Features extracted for {len(df)} reviews\")\n",
    "    print(f\"   - Average review length: {df['review_length'].mean():.1f} characters\")\n",
    "    print(f\"   - Average word count: {df['word_count'].mean():.1f} words\")\n",
    "    print(f\"   - Reviews with URLs: {df['has_url'].sum()}\")\n",
    "    print(f\"   - Reviews with promotional words: {(df['promotional_words'] > 0).sum()}\")\n",
    "    print(f\"   - Reviews with irrelevant content: {(df['irrelevant_words'] > 0).sum()}\")\n",
    "    print(f\"   - Reviews with fake rant indicators: {(df['fake_rant_words'] > 0).sum()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a97eb",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 4: Manual Labeling (Create Ground Truth)\n",
    "\n",
    "Let's manually label our sample data to create ground truth for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd89c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_manual_labels(df):\n",
    "    \"\"\"\n",
    "    Create manual labels for the sample data\n",
    "    In a real scenario, you would label a larger subset manually\n",
    "    \"\"\"\n",
    "    print(\"üè∑Ô∏è CREATING MANUAL LABELS FOR GROUND TRUTH\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Manual labels based on our sample data\n",
    "    # 0 = No violation, 1 = Violation\n",
    "    \n",
    "    # Advertisement labels (reviews 3, 4, 5 in our sample)\n",
    "    ad_labels = [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    # Irrelevant content labels (reviews 6, 7, 8 in our sample)\n",
    "    irrelevant_labels = [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "    \n",
    "    # Fake rant labels (reviews 9, 10, 11 in our sample)\n",
    "    fake_rant_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "    \n",
    "    df['is_advertisement'] = ad_labels\n",
    "    df['is_irrelevant'] = irrelevant_labels\n",
    "    df['is_fake_rant'] = fake_rant_labels\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"üìä Label Summary:\")\n",
    "    print(f\"  Advertisements: {df['is_advertisement'].sum()}/{len(df)} ({df['is_advertisement'].sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Irrelevant: {df['is_irrelevant'].sum()}/{len(df)} ({df['is_irrelevant'].sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Fake Rants: {df['is_fake_rant'].sum()}/{len(df)} ({df['is_fake_rant'].sum()/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_manual_labels(df)\n",
    "print(\"\\n‚úÖ Manual labels created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b14dcc",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: Simple Rule-Based Classifier (Baseline)\n",
    "\n",
    "Let's start with a simple rule-based approach as our baseline before moving to ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91969d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRuleBasedClassifier:\n",
    "    \"\"\"\n",
    "    Simple rule-based classifier for policy violation detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define keywords for each violation type\n",
    "        self.ad_keywords = [\n",
    "            'visit', 'website', 'www', 'http', 'call', 'phone', 'discount',\n",
    "            'deal', 'promo', 'sale', 'coupon', 'special offer'\n",
    "        ]\n",
    "        \n",
    "        self.irrelevant_keywords = [\n",
    "            'my phone', 'my car', 'politics', 'weather', 'traffic',\n",
    "            'my day', 'my life', 'news', 'government'\n",
    "        ]\n",
    "        \n",
    "        self.fake_rant_keywords = [\n",
    "            'never been', 'heard it', 'looks like', 'probably',\n",
    "            'i hate these', 'all these places', 'never visited'\n",
    "        ]\n",
    "    \n",
    "    def classify_advertisement(self, text):\n",
    "        \"\"\"Check if review contains advertisement\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.ad_keywords)\n",
    "    \n",
    "    def classify_irrelevant(self, text):\n",
    "        \"\"\"Check if review contains irrelevant content\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.irrelevant_keywords)\n",
    "    \n",
    "    def classify_fake_rant(self, text):\n",
    "        \"\"\"Check if review is a fake rant\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword in text_lower for keyword in self.fake_rant_keywords)\n",
    "    \n",
    "    def classify_review(self, text):\n",
    "        \"\"\"Classify a single review for all violation types\"\"\"\n",
    "        return {\n",
    "            'advertisement': self.classify_advertisement(text),\n",
    "            'irrelevant': self.classify_irrelevant(text),\n",
    "            'fake_rant': self.classify_fake_rant(text)\n",
    "        }\n",
    "    \n",
    "    def classify_batch(self, texts):\n",
    "        \"\"\"Classify multiple reviews\"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            results.append(self.classify_review(text))\n",
    "        return results\n",
    "\n",
    "# Test the rule-based classifier\n",
    "print(\"ü§ñ TESTING RULE-BASED CLASSIFIER\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "classifier = SimpleRuleBasedClassifier()\n",
    "\n",
    "# Get predictions\n",
    "reviews = df['review_text'].tolist()\n",
    "predictions = classifier.classify_batch(reviews)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df['pred_advertisement'] = [pred['advertisement'] for pred in predictions]\n",
    "df['pred_irrelevant'] = [pred['irrelevant'] for pred in predictions]\n",
    "df['pred_fake_rant'] = [pred['fake_rant'] for pred in predictions]\n",
    "\n",
    "print(\"‚úÖ Rule-based classification complete!\")\n",
    "print(f\"\\nüìä Prediction Summary:\")\n",
    "print(f\"  Predicted Advertisements: {df['pred_advertisement'].sum()}\")\n",
    "print(f\"  Predicted Irrelevant: {df['pred_irrelevant'].sum()}\")\n",
    "print(f\"  Predicted Fake Rants: {df['pred_fake_rant'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d05ff",
   "metadata": {},
   "source": [
    "## üìä Step 6: Evaluation and Metrics\n",
    "\n",
    "Let's evaluate our rule-based classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(df, violation_type):\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance for a specific violation type\n",
    "    \"\"\"\n",
    "    true_col = f'is_{violation_type}'\n",
    "    pred_col = f'pred_{violation_type}'\n",
    "    \n",
    "    y_true = df[true_col].tolist()\n",
    "    y_pred = df[pred_col].tolist()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    accuracy = sum(t == p for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(df, violation_type):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for a violation type\n",
    "    \"\"\"\n",
    "    true_col = f'is_{violation_type}'\n",
    "    pred_col = f'pred_{violation_type}'\n",
    "    \n",
    "    y_true = df[true_col].tolist()\n",
    "    y_pred = df[pred_col].tolist()\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=['No Violation', 'Violation'],\n",
    "               yticklabels=['No Violation', 'Violation'])\n",
    "    plt.title(f'Confusion Matrix - {violation_type.title()} Detection')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate all violation types\n",
    "print(\"üìä RULE-BASED CLASSIFIER EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "violation_types = ['advertisement', 'irrelevant', 'fake_rant']\n",
    "results = {}\n",
    "\n",
    "for vtype in violation_types:\n",
    "    metrics = evaluate_classifier(df, vtype)\n",
    "    results[vtype] = metrics\n",
    "    \n",
    "    print(f\"\\nüéØ {vtype.upper()} DETECTION:\")\n",
    "    print(f\"  Precision: {metrics['precision']:.3f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.3f}\")\n",
    "    print(f\"  F1-Score:  {metrics['f1_score']:.3f}\")\n",
    "    print(f\"  Accuracy:  {metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(df, vtype)\n",
    "\n",
    "# Overall average F1-score\n",
    "avg_f1 = np.mean([results[vtype]['f1_score'] for vtype in violation_types])\n",
    "print(f\"\\nüèÜ OVERALL AVERAGE F1-SCORE: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcaa4a",
   "metadata": {},
   "source": [
    "## üîÆ Step 7: Prepare for ML Models (Next Session)\n",
    "\n",
    "Let's set up the foundation for using Hugging Face models in our next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc771731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_huggingface_models():\n",
    "    \"\"\"\n",
    "    Test Hugging Face model loading for next session\n",
    "    \"\"\"\n",
    "    print(\"üîÆ PREPARING FOR ML MODELS (DAY 2)\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    try:\n",
    "        # Test loading a simple classification model\n",
    "        print(\"Testing model loading...\")\n",
    "        classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            device=-1  # Use CPU\n",
    "        )\n",
    "        \n",
    "        # Test on a sample review\n",
    "        test_review = \"Great food and excellent service!\"\n",
    "        result = classifier(test_review)\n",
    "        \n",
    "        print(f\"‚úÖ Model loading successful!\")\n",
    "        print(f\"Test result: {result}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model loading failed: {e}\")\n",
    "        print(\"This is okay - we'll set this up properly in Day 2\")\n",
    "        return False\n",
    "\n",
    "model_ready = setup_huggingface_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bac5c1",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save Progress and Plan Next Steps\n",
    "\n",
    "Let's save our work and prepare for tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for next session\n",
    "df.to_csv('processed_reviews_day1.csv', index=False)\n",
    "print(\"üíæ Data saved to 'processed_reviews_day1.csv'\")\n",
    "\n",
    "# Save results summary\n",
    "summary = {\n",
    "    'day': 1,\n",
    "    'date': '2025-08-25',\n",
    "    'dataset_size': len(df),\n",
    "    'features_extracted': len([col for col in df.columns if col.startswith(('has_', 'is_', 'pred_'))]),\n",
    "    'baseline_results': results,\n",
    "    'avg_f1_score': avg_f1,\n",
    "    'next_steps': [\n",
    "        'Implement Hugging Face models',\n",
    "        'Improve prompt engineering',\n",
    "        'Test on larger dataset',\n",
    "        'Create ensemble approach'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('day1_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"üìÑ Summary saved to 'day1_summary.json'\")\n",
    "\n",
    "print(\"\\nüéâ DAY 1 COMPLETE!\")\n",
    "print(\"=\" * 20)\n",
    "print(\"‚úÖ Environment set up\")\n",
    "print(\"‚úÖ Data loaded and explored\")\n",
    "print(\"‚úÖ Features extracted\")\n",
    "print(\"‚úÖ Baseline classifier implemented\")\n",
    "print(\"‚úÖ Evaluation metrics calculated\")\n",
    "print(f\"‚úÖ Baseline F1-score: {avg_f1:.3f}\")\n",
    "\n",
    "print(\"\\nüìÖ TOMORROW'S PLAN (Day 2):\")\n",
    "print(\"üéØ Implement Hugging Face models\")\n",
    "print(\"üéØ Create smart prompts for LLMs\")\n",
    "print(\"üéØ Test and improve accuracy\")\n",
    "print(\"üéØ Prepare for demo creation\")\n",
    "\n",
    "print(\"\\nüèÜ Great job! You're on track to win this hackathon! üèÜ\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
