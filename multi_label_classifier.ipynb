{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35cc1e0b",
   "metadata": {},
   "source": [
    "# Multi-Label Review Classification with Hugging Face Transformers\n",
    "\n",
    "This notebook implements a multi-label classification system to predict:\n",
    "\n",
    "- `is_spam`: Whether a review is spam (1) or not (0)\n",
    "- `is_advertisement`: Whether a review is an advertisement (1) or not (0)\n",
    "- `is_rant_without_visit`: Whether a review is a rant without actual visit (1) or not (0)\n",
    "\n",
    "The model uses both review text and metadata features for prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbc8aa",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794ef3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063416",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset (1000 rows)\n",
    "\n",
    "Generate a realistic dataset with diverse review types and multi-label scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ffb695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 1000 rows\n",
      "Dataset shape: (1000, 20)\n",
      "\n",
      "First 3 rows:\n",
      "              user_id user_name           time  rating  \\\n",
      "0  228355989445507485    User_1  1565605751383       2   \n",
      "1  925514409025013289    User_2  1691769793417       5   \n",
      "2  513875040606644119    User_3  1598129241107       5   \n",
      "\n",
      "                                             text   pics  resp  \\\n",
      "0  Wow! Such an amazing experience! Unbelievable!   True  None   \n",
      "1   The food was delicious and service was quick.  False  None   \n",
      "2  Good experience overall. Will come back again.  False  None   \n",
      "\n",
      "                             gmap_id        biz_name  \\\n",
      "0  0x1b410b5202ad6d:0x150123892c6150   Downtown Cafe   \n",
      "1   0xc746f3ba09dac:0x1f5ecd73fd558b     Joe's Diner   \n",
      "2   0x12411a5f9633d0:0x78c122e0cbe85  Medical Clinic   \n",
      "\n",
      "                      description    category  avg_rating  num_of_reviews  \\\n",
      "0   Description for Downtown Cafe     Finance         3.2              16   \n",
      "1     Description for Joe's Diner  Healthcare         4.0             175   \n",
      "2  Description for Medical Clinic  Technology         3.5             425   \n",
      "\n",
      "     hours                    address  price_level         state  is_spam  \\\n",
      "0     None  3911 Main St, City, State            4  Sample State        1   \n",
      "1     None  3627 Main St, City, State            2  Sample State        0   \n",
      "2  9AM-5PM  6025 Main St, City, State            4  Sample State        0   \n",
      "\n",
      "   is_advertisement  is_rant_without_visit  \n",
      "0                 0                      0  \n",
      "1                 0                      0  \n",
      "2                 0                      0  \n"
     ]
    }
   ],
   "source": [
    "def generate_sample_data(n_samples=1000):\n",
    "    \"\"\"Generate realistic sample review data with multi-label targets\"\"\"\n",
    "\n",
    "    # Sample business names and categories\n",
    "    businesses = [\n",
    "        \"Joe's Diner\",\n",
    "        \"Tech Solutions Inc\",\n",
    "        \"Downtown Cafe\",\n",
    "        \"City Hospital\",\n",
    "        \"SuperMart\",\n",
    "        \"Luxury Hotel\",\n",
    "        \"Fast Food Corner\",\n",
    "        \"Auto Repair Shop\",\n",
    "        \"Beauty Salon\",\n",
    "        \"Fitness Center\",\n",
    "        \"Book Store\",\n",
    "        \"Pizza Palace\",\n",
    "        \"Medical Clinic\",\n",
    "        \"Shopping Mall\",\n",
    "        \"Gas Station\",\n",
    "        \"Bank Branch\",\n",
    "    ]\n",
    "\n",
    "    categories = [\n",
    "        \"Restaurant\",\n",
    "        \"Technology\",\n",
    "        \"Healthcare\",\n",
    "        \"Retail\",\n",
    "        \"Hotel\",\n",
    "        \"Automotive\",\n",
    "        \"Beauty\",\n",
    "        \"Fitness\",\n",
    "        \"Food\",\n",
    "        \"Finance\",\n",
    "    ]\n",
    "\n",
    "    # Sample review templates for different types\n",
    "    legitimate_reviews = [\n",
    "        \"Great service and friendly staff. Highly recommend!\",\n",
    "        \"Good experience overall. Will come back again.\",\n",
    "        \"Nice atmosphere and reasonable prices.\",\n",
    "        \"Staff was helpful and the place was clean.\",\n",
    "        \"Excellent quality and fast service.\",\n",
    "        \"Had a pleasant experience here.\",\n",
    "        \"The food was delicious and service was quick.\",\n",
    "        \"Clean facilities and professional staff.\",\n",
    "    ]\n",
    "\n",
    "    spam_reviews = [\n",
    "        \"Best place ever!!! 5 stars always!!!\",\n",
    "        \"Amazing amazing amazing! You must visit!\",\n",
    "        \"Perfect perfect perfect! No complaints!\",\n",
    "        \"Incredible service! Outstanding! Fantastic!\",\n",
    "        \"Wow! Such an amazing experience! Unbelievable!\",\n",
    "    ]\n",
    "\n",
    "    advertisement_reviews = [\n",
    "        \"Check out their new website at www.example.com for great deals!\",\n",
    "        \"Visit our store and get 50% off all items this weekend!\",\n",
    "        \"Call 555-1234 for special promotions and discounts!\",\n",
    "        \"New menu available! Try our premium dishes today!\",\n",
    "        \"Follow us on social media for exclusive offers!\",\n",
    "    ]\n",
    "\n",
    "    rant_reviews = [\n",
    "        \"Terrible place! Never going back! Worst service ever!\",\n",
    "        \"This business should be shut down! Horrible experience!\",\n",
    "        \"Waste of time and money! Staff is rude and unprofessional!\",\n",
    "        \"I demand a refund! This place is a disaster!\",\n",
    "        \"Absolutely disgusting! Management doesn't care!\",\n",
    "    ]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Generate basic review data\n",
    "        user_id = f\"{random.randint(10**17, 10**18)}\"\n",
    "        user_name = f\"User_{i+1}\"\n",
    "        time = random.randint(1500000000000, 1700000000000)  # Random timestamp\n",
    "        rating = random.randint(1, 5)\n",
    "        pics = random.choice([True, False])\n",
    "        resp = None if random.random() > 0.2 else \"Thank you for your feedback!\"\n",
    "        gmap_id = (\n",
    "            f\"0x{random.randint(10**15, 10**16):x}:0x{random.randint(10**15, 10**16):x}\"\n",
    "        )\n",
    "        biz_name = random.choice(businesses)\n",
    "        description = f\"Description for {biz_name}\"\n",
    "        category = random.choice(categories)\n",
    "        avg_rating = round(random.uniform(2.0, 4.8), 1)\n",
    "        num_of_reviews = random.randint(1, 500)\n",
    "        hours = \"9AM-5PM\" if random.random() > 0.3 else None\n",
    "        address = f\"{random.randint(100, 9999)} Main St, City, State\"\n",
    "        price_level = random.randint(0, 4)\n",
    "        state = \"Sample State\"\n",
    "\n",
    "        # Determine review type and labels (multi-label possible)\n",
    "        review_type = random.choices(\n",
    "            [\n",
    "                \"legitimate\",\n",
    "                \"spam\",\n",
    "                \"advertisement\",\n",
    "                \"rant\",\n",
    "                \"spam_ad\",\n",
    "                \"spam_rant\",\n",
    "                \"ad_rant\",\n",
    "            ],\n",
    "            weights=[0.6, 0.1, 0.1, 0.1, 0.05, 0.025, 0.025],\n",
    "        )[0]\n",
    "\n",
    "        # Initialize labels\n",
    "        is_spam = 0\n",
    "        is_advertisement = 0\n",
    "        is_rant_without_visit = 0\n",
    "\n",
    "        # Generate text and labels based on type\n",
    "        if review_type == \"legitimate\":\n",
    "            text = random.choice(legitimate_reviews)\n",
    "        elif review_type == \"spam\":\n",
    "            text = random.choice(spam_reviews)\n",
    "            is_spam = 1\n",
    "        elif review_type == \"advertisement\":\n",
    "            text = random.choice(advertisement_reviews)\n",
    "            is_advertisement = 1\n",
    "        elif review_type == \"rant\":\n",
    "            text = random.choice(rant_reviews)\n",
    "            is_rant_without_visit = 1\n",
    "        elif review_type == \"spam_ad\":  # Multi-label: both spam and ad\n",
    "            text = (\n",
    "                f\"{random.choice(spam_reviews)} {random.choice(advertisement_reviews)}\"\n",
    "            )\n",
    "            is_spam = 1\n",
    "            is_advertisement = 1\n",
    "        elif review_type == \"spam_rant\":  # Multi-label: both spam and rant\n",
    "            text = f\"{random.choice(spam_reviews)} {random.choice(rant_reviews)}\"\n",
    "            is_spam = 1\n",
    "            is_rant_without_visit = 1\n",
    "        elif review_type == \"ad_rant\":  # Multi-label: both ad and rant\n",
    "            text = (\n",
    "                f\"{random.choice(advertisement_reviews)} {random.choice(rant_reviews)}\"\n",
    "            )\n",
    "            is_advertisement = 1\n",
    "            is_rant_without_visit = 1\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"user_id\": user_id,\n",
    "                \"user_name\": user_name,\n",
    "                \"time\": time,\n",
    "                \"rating\": rating,\n",
    "                \"text\": text,\n",
    "                \"pics\": pics,\n",
    "                \"resp\": resp,\n",
    "                \"gmap_id\": gmap_id,\n",
    "                \"biz_name\": biz_name,\n",
    "                \"description\": description,\n",
    "                \"category\": category,\n",
    "                \"avg_rating\": avg_rating,\n",
    "                \"num_of_reviews\": num_of_reviews,\n",
    "                \"hours\": hours,\n",
    "                \"address\": address,\n",
    "                \"price_level\": price_level,\n",
    "                \"state\": state,\n",
    "                \"is_spam\": is_spam,\n",
    "                \"is_advertisement\": is_advertisement,\n",
    "                \"is_rant_without_visit\": is_rant_without_visit,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate the dataset\n",
    "df = generate_sample_data(1000)\n",
    "\n",
    "print(f\"Dataset created with {len(df)} rows\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d2d3d",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset and Label Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42695cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LABEL DISTRIBUTION ===\n",
      "is_spam:\n",
      "  Positive (1): 161 (16.1%)\n",
      "  Negative (0): 839 (83.9%)\n",
      "is_advertisement:\n",
      "  Positive (1): 185 (18.5%)\n",
      "  Negative (0): 815 (81.5%)\n",
      "is_rant_without_visit:\n",
      "  Positive (1): 146 (14.6%)\n",
      "  Negative (0): 854 (85.4%)\n",
      "\n",
      "=== MULTI-LABEL COMBINATIONS ===\n",
      "Legitimate: 609 (60.9%)\n",
      "Advertisement only: 109 (10.9%)\n",
      "Rant only: 99 (9.9%)\n",
      "Spam only: 82 (8.2%)\n",
      "Spam + Advertisement: 54 (5.4%)\n",
      "Spam + Rant: 25 (2.5%)\n",
      "Advertisement + Rant: 22 (2.2%)\n",
      "\n",
      "=== SAMPLE REVIEWS BY TYPE ===\n",
      "\n",
      "Legitimate:\n",
      "'The food was delicious and service was quick....' (Rating: 5)\n",
      "\n",
      "Spam only:\n",
      "'Wow! Such an amazing experience! Unbelievable!...' (Rating: 2)\n",
      "\n",
      "Advertisement only:\n",
      "'Visit our store and get 50% off all items this weekend!...' (Rating: 3)\n",
      "\n",
      "Rant only:\n",
      "'Waste of time and money! Staff is rude and unprofessional!...' (Rating: 5)\n",
      "\n",
      "Spam + Advertisement:\n",
      "'Amazing amazing amazing! You must visit! Call 555-1234 for special promotions and discounts!...' (Rating: 1)\n",
      "\n",
      "Spam + Rant:\n",
      "'Wow! Such an amazing experience! Unbelievable! Waste of time and money! Staff is rude and unprofessi...' (Rating: 5)\n",
      "\n",
      "Advertisement + Rant:\n",
      "'Call 555-1234 for special promotions and discounts! I demand a refund! This place is a disaster!...' (Rating: 4)\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "print(\"=== LABEL DISTRIBUTION ===\")\n",
    "target_cols = [\"is_spam\", \"is_advertisement\", \"is_rant_without_visit\"]\n",
    "\n",
    "for col in target_cols:\n",
    "    positive_count = df[col].sum()\n",
    "    negative_count = len(df) - positive_count\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Positive (1): {positive_count} ({positive_count/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Negative (0): {negative_count} ({negative_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Check multi-label combinations\n",
    "print(\"\\n=== MULTI-LABEL COMBINATIONS ===\")\n",
    "df[\"label_combination\"] = df[target_cols].apply(\n",
    "    lambda x: \"\".join(x.astype(str)), axis=1\n",
    ")\n",
    "combination_counts = df[\"label_combination\"].value_counts()\n",
    "\n",
    "label_map = {\n",
    "    \"000\": \"Legitimate\",\n",
    "    \"100\": \"Spam only\",\n",
    "    \"010\": \"Advertisement only\",\n",
    "    \"001\": \"Rant only\",\n",
    "    \"110\": \"Spam + Advertisement\",\n",
    "    \"101\": \"Spam + Rant\",\n",
    "    \"011\": \"Advertisement + Rant\",\n",
    "    \"111\": \"All three labels\",\n",
    "}\n",
    "\n",
    "for combo, count in combination_counts.items():\n",
    "    label_desc = label_map.get(combo, combo)\n",
    "    print(f\"{label_desc}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Show sample reviews for each type\n",
    "print(\"\\n=== SAMPLE REVIEWS BY TYPE ===\")\n",
    "for combo, description in label_map.items():\n",
    "    if combo in combination_counts.index:\n",
    "        sample_text = df[df[\"label_combination\"] == combo][\"text\"].iloc[0]\n",
    "        print(f\"\\n{description}:\")\n",
    "        print(\n",
    "            f\"'{sample_text[:100]}...' (Rating: {df[df['label_combination'] == combo]['rating'].iloc[0]})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13911a7c",
   "metadata": {},
   "source": [
    "## 4. Prepare Features for Multi-Label Classification\n",
    "\n",
    "Combine text and metadata features for better prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ae8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1000 text samples\n",
      "Sample combined text (first 200 chars):\n",
      "'Review: Wow! Such an amazing experience! Unbelievable! Business: Downtown Cafe Category: Finance Rating: 2/5 Avg Rating: 3.2/5 Reviews: 16 Price: 4 Has Photos: True...'\n",
      "\n",
      "Corresponding labels: [1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def prepare_features(df):\n",
    "    \"\"\"Prepare combined text and metadata features\"\"\"\n",
    "\n",
    "    # Create combined text feature including metadata\n",
    "    df[\"combined_text\"] = df.apply(\n",
    "        lambda row: f\"Review: {row['text']} \"\n",
    "        f\"Business: {row['biz_name']} \"\n",
    "        f\"Category: {row['category']} \"\n",
    "        f\"Rating: {row['rating']}/5 \"\n",
    "        f\"Avg Rating: {row['avg_rating']}/5 \"\n",
    "        f\"Reviews: {row['num_of_reviews']} \"\n",
    "        f\"Price: {row['price_level']} \"\n",
    "        f\"Has Photos: {row['pics']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Prepare labels as multi-label format\n",
    "    labels = df[target_cols].values.tolist()\n",
    "\n",
    "    return df[\"combined_text\"].tolist(), labels\n",
    "\n",
    "\n",
    "# Prepare features\n",
    "texts, labels = prepare_features(df)\n",
    "\n",
    "print(f\"Prepared {len(texts)} text samples\")\n",
    "print(f\"Sample combined text (first 200 chars):\")\n",
    "print(f\"'{texts[0][:200]}...'\")\n",
    "print(f\"\\nCorresponding labels: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629338da",
   "metadata": {},
   "source": [
    "## 5. Load Pre-trained Transformer Model\n",
    "\n",
    "Using DistilBERT as a lightweight but effective model for multi-label classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9042be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: distilbert-base-uncased\n",
      "Model parameters: 66,955,779\n",
      "Device: CPU\n",
      "Model moved to: cpu\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 3  # is_spam, is_advertisement, is_rant_without_visit\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\",  # Important for multi-label\n",
    "    id2label={0: \"is_spam\", 1: \"is_advertisement\", 2: \"is_rant_without_visit\"},\n",
    "    label2id={\"is_spam\": 0, \"is_advertisement\": 1, \"is_rant_without_visit\": 2},\n",
    ")\n",
    "\n",
    "print(f\"Loaded model: {MODEL_NAME}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model moved to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfbd42",
   "metadata": {},
   "source": [
    "## 6. Train-Test Split and Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d68aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 800\n",
      "Test samples: 200\n",
      "Dataset objects created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=df[\"label_combination\"]\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "\n",
    "# Create training dataset\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "\n",
    "# Create Dataset objects\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = ReviewDataset(train_encodings, y_train)\n",
    "test_dataset = ReviewDataset(test_encodings, y_test)\n",
    "\n",
    "print(\"Dataset objects created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064f6f1",
   "metadata": {},
   "source": [
    "## 7. Training Configuration and Custom Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1180cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration set up successfully!\n",
      "Training epochs: 3\n",
      "Batch size: 8\n",
      "MLflow and other logging integrations disabled.\n"
     ]
    }
   ],
   "source": [
    "# Define custom metrics for multi-label classification\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Apply sigmoid and threshold at 0.5 for multi-label classification\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    predictions = sigmoid(torch.Tensor(predictions))\n",
    "    predictions = (predictions > 0.5).int().numpy()\n",
    "\n",
    "    # Calculate metrics for each label\n",
    "    results = {}\n",
    "    label_names = [\"is_spam\", \"is_advertisement\", \"is_rant_without_visit\"]\n",
    "\n",
    "    for i, label_name in enumerate(label_names):\n",
    "        true_labels = labels[:, i]\n",
    "        pred_labels = predictions[:, i]\n",
    "\n",
    "        f1 = f1_score(true_labels, pred_labels, average=\"binary\")\n",
    "        precision = precision_score(\n",
    "            true_labels, pred_labels, average=\"binary\", zero_division=0\n",
    "        )\n",
    "        recall = recall_score(\n",
    "            true_labels, pred_labels, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "        results[f\"{label_name}_f1\"] = f1\n",
    "        results[f\"{label_name}_precision\"] = precision\n",
    "        results[f\"{label_name}_recall\"] = recall\n",
    "\n",
    "    # Overall metrics\n",
    "    results[\"macro_f1\"] = f1_score(labels, predictions, average=\"macro\")\n",
    "    results[\"micro_f1\"] = f1_score(labels, predictions, average=\"micro\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Training arguments with proper logging disabled\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=[],  # Empty list to disable all logging\n",
    "    disable_tqdm=False,  # Keep progress bars\n",
    ")\n",
    "\n",
    "print(\"Training configuration set up successfully!\")\n",
    "print(f\"Training epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(\"MLflow and other logging integrations disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abf6b9",
   "metadata": {},
   "source": [
    "## 8. Train the Multi-Label Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08428d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up existing MLflow directory\n",
      "Trainer initialized successfully\n",
      "Starting training...\n",
      "This may take several minutes depending on your hardware.\n",
      "Trainer initialized successfully\n",
      "Starting training...\n",
      "This may take several minutes depending on your hardware.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 00:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Is Spam F1</th>\n",
       "      <th>Is Spam Precision</th>\n",
       "      <th>Is Spam Recall</th>\n",
       "      <th>Is Advertisement F1</th>\n",
       "      <th>Is Advertisement Precision</th>\n",
       "      <th>Is Advertisement Recall</th>\n",
       "      <th>Is Rant Without Visit F1</th>\n",
       "      <th>Is Rant Without Visit Precision</th>\n",
       "      <th>Is Rant Without Visit Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.971930</td>\n",
       "      <td>0.973822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "Training loss: 0.1418\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing MLflow runs to prevent conflicts\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Remove mlruns directory if it exists and is corrupted\n",
    "if os.path.exists(\"./mlruns\"):\n",
    "    try:\n",
    "        shutil.rmtree(\"./mlruns\")\n",
    "        print(\"Cleaned up existing MLflow directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not clean MLflow directory: {e}\")\n",
    "\n",
    "# Initialize trainer with error handling\n",
    "try:\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    )\n",
    "    print(\"Trainer initialized successfully\")\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    print(\"This may take several minutes depending on your hardware.\")\n",
    "\n",
    "    # Train the model\n",
    "    train_result = trainer.train()\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    print(\"Attempting to train without MLflow integration...\")\n",
    "\n",
    "    # Set environment variable to disable MLflow\n",
    "    os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n",
    "\n",
    "    # Try again with additional safeguards\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    )\n",
    "\n",
    "    print(\"Retrying training...\")\n",
    "    train_result = trainer.train()\n",
    "    print(\"Training completed on retry!\")\n",
    "    print(f\"Training loss: {train_result.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad72f7",
   "metadata": {},
   "source": [
    "## 8b. Alternative Training (if above fails)\n",
    "\n",
    "If the Trainer approach fails due to MLflow issues, use this simpler training loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf43bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative training approach without Trainer class\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def alternative_training():\n",
    "    print(\"Using alternative training approach...\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_epochs = 3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "            # Move batch to device\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Print progress every 50 batches\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                avg_loss = epoch_loss / (batch_idx + 1)\n",
    "                print(f\"  Batch {batch_idx + 1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        total_loss += avg_epoch_loss\n",
    "        print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        # Simple evaluation\n",
    "        if (epoch + 1) % 1 == 0:  # Evaluate every epoch\n",
    "            model.eval()\n",
    "            eval_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    input_ids = batch[\"input_ids\"].to(device)\n",
    "                    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels,\n",
    "                    )\n",
    "                    eval_loss += outputs.loss.item()\n",
    "\n",
    "            avg_eval_loss = eval_loss / len(test_loader)\n",
    "            print(f\"Evaluation Loss: {avg_eval_loss:.4f}\")\n",
    "            model.train()\n",
    "\n",
    "    avg_training_loss = total_loss / num_epochs\n",
    "    print(f\"\\nAlternative training completed!\")\n",
    "    print(f\"Average training loss: {avg_training_loss:.4f}\")\n",
    "\n",
    "    return avg_training_loss\n",
    "\n",
    "\n",
    "# Uncomment the line below if you need to use alternative training\n",
    "# alternative_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602f934",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d5d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL EVALUATION RESULTS ===\n",
      "Test Loss: 0.0132\n",
      "\n",
      "=== PER-LABEL METRICS ===\n",
      "\n",
      "IS_SPAM:\n",
      "  F1 Score:   1.0000\n",
      "  Precision:  1.0000\n",
      "  Recall:     1.0000\n",
      "\n",
      "IS_ADVERTISEMENT:\n",
      "  F1 Score:   1.0000\n",
      "  Precision:  1.0000\n",
      "  Recall:     1.0000\n",
      "\n",
      "IS_RANT_WITHOUT_VISIT:\n",
      "  F1 Score:   1.0000\n",
      "  Precision:  1.0000\n",
      "  Recall:     1.0000\n",
      "\n",
      "=== OVERALL METRICS ===\n",
      "Macro F1:  1.0000\n",
      "Micro F1:  1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"=== MODEL EVALUATION RESULTS ===\")\n",
    "print(f\"Test Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(\"\\n=== PER-LABEL METRICS ===\")\n",
    "\n",
    "label_names = [\"is_spam\", \"is_advertisement\", \"is_rant_without_visit\"]\n",
    "for label in label_names:\n",
    "    f1 = eval_results.get(f\"eval_{label}_f1\", 0)\n",
    "    precision = eval_results.get(f\"eval_{label}_precision\", 0)\n",
    "    recall = eval_results.get(f\"eval_{label}_recall\", 0)\n",
    "\n",
    "    print(f\"\\n{label.upper()}:\")\n",
    "    print(f\"  F1 Score:   {f1:.4f}\")\n",
    "    print(f\"  Precision:  {precision:.4f}\")\n",
    "    print(f\"  Recall:     {recall:.4f}\")\n",
    "\n",
    "print(\"\\n=== OVERALL METRICS ===\")\n",
    "print(f\"Macro F1:  {eval_results.get('eval_macro_f1', 0):.4f}\")\n",
    "print(f\"Micro F1:  {eval_results.get('eval_micro_f1', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c5c81",
   "metadata": {},
   "source": [
    "## 10. Detailed Prediction Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f8e6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LABEL-WISE ACCURACY ===\n",
      "Spam Detection Accuracy:        1.0000\n",
      "Advertisement Detection Accuracy: 1.0000\n",
      "Rant Detection Accuracy:        1.0000\n",
      "\n",
      "=== EXAMPLE PREDICTIONS ===\n",
      "(Showing first 5 test samples)\n",
      "\n",
      "Format: [True Labels] -> [Predicted Labels] (Probabilities)\n",
      "\n",
      "Sample 1:\n",
      "Text: Review: Check out their new website at www.example.com for great deals! Terrible place! Never going ...\n",
      "True:  [np.int64(0), np.int64(1), np.int64(1)] -> Pred: [np.int64(0), np.int64(1), np.int64(1)]\n",
      "Probabilities: [Spam: 0.047, Ad: 0.943, Rant: 0.927]\n",
      "\n",
      "Sample 2:\n",
      "Text: Review: Clean facilities and professional staff. Business: Shopping Mall Category: Healthcare Rating...\n",
      "True:  [np.int64(0), np.int64(0), np.int64(0)] -> Pred: [np.int64(0), np.int64(0), np.int64(0)]\n",
      "Probabilities: [Spam: 0.004, Ad: 0.005, Rant: 0.004]\n",
      "\n",
      "Sample 3:\n",
      "Text: Review: Call 555-1234 for special promotions and discounts! This business should be shut down! Horri...\n",
      "True:  [np.int64(0), np.int64(1), np.int64(1)] -> Pred: [np.int64(0), np.int64(1), np.int64(1)]\n",
      "Probabilities: [Spam: 0.041, Ad: 0.931, Rant: 0.931]\n",
      "\n",
      "Sample 4:\n",
      "Text: Review: Excellent quality and fast service. Business: City Hospital Category: Hotel Rating: 2/5 Avg ...\n",
      "True:  [np.int64(0), np.int64(0), np.int64(0)] -> Pred: [np.int64(0), np.int64(0), np.int64(0)]\n",
      "Probabilities: [Spam: 0.004, Ad: 0.004, Rant: 0.004]\n",
      "\n",
      "Sample 5:\n",
      "Text: Review: Amazing amazing amazing! You must visit! Absolutely disgusting! Management doesn't care! Bus...\n",
      "True:  [np.int64(1), np.int64(0), np.int64(1)] -> Pred: [np.int64(1), np.int64(0), np.int64(1)]\n",
      "Probabilities: [Spam: 0.920, Ad: 0.040, Rant: 0.957]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Process predictions\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(torch.Tensor(predictions.predictions)).numpy()\n",
    "pred_labels = (probs > 0.5).astype(int)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [X_test[i][:100] + \"...\" for i in range(len(X_test))],  # Truncated text\n",
    "        \"true_spam\": [y_test[i][0] for i in range(len(y_test))],\n",
    "        \"true_ad\": [y_test[i][1] for i in range(len(y_test))],\n",
    "        \"true_rant\": [y_test[i][2] for i in range(len(y_test))],\n",
    "        \"pred_spam\": pred_labels[:, 0],\n",
    "        \"pred_ad\": pred_labels[:, 1],\n",
    "        \"pred_rant\": pred_labels[:, 2],\n",
    "        \"prob_spam\": probs[:, 0],\n",
    "        \"prob_ad\": probs[:, 1],\n",
    "        \"prob_rant\": probs[:, 2],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate accuracy for each label\n",
    "print(\"=== LABEL-WISE ACCURACY ===\")\n",
    "spam_acc = (test_df[\"true_spam\"] == test_df[\"pred_spam\"]).mean()\n",
    "ad_acc = (test_df[\"true_ad\"] == test_df[\"pred_ad\"]).mean()\n",
    "rant_acc = (test_df[\"true_rant\"] == test_df[\"pred_rant\"]).mean()\n",
    "\n",
    "print(f\"Spam Detection Accuracy:        {spam_acc:.4f}\")\n",
    "print(f\"Advertisement Detection Accuracy: {ad_acc:.4f}\")\n",
    "print(f\"Rant Detection Accuracy:        {rant_acc:.4f}\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\n=== EXAMPLE PREDICTIONS ===\")\n",
    "print(\"(Showing first 5 test samples)\")\n",
    "print(\"\\nFormat: [True Labels] -> [Predicted Labels] (Probabilities)\")\n",
    "\n",
    "for i in range(min(5, len(test_df))):\n",
    "    row = test_df.iloc[i]\n",
    "    true_labels = [row[\"true_spam\"], row[\"true_ad\"], row[\"true_rant\"]]\n",
    "    pred_labels = [row[\"pred_spam\"], row[\"pred_ad\"], row[\"pred_rant\"]]\n",
    "    probs = [row[\"prob_spam\"], row[\"prob_ad\"], row[\"prob_rant\"]]\n",
    "\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"True:  {true_labels} -> Pred: {pred_labels}\")\n",
    "    print(\n",
    "        f\"Probabilities: [Spam: {probs[0]:.3f}, Ad: {probs[1]:.3f}, Rant: {probs[2]:.3f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867257d1",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrix and Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f3af286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED CLASSIFICATION REPORT ===\n",
      "\n",
      "IS_SPAM Classification Report:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, label_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(target_names):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mlabel_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Classification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     14\u001b[39m         classification_report(\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m             y_true[:, i], \u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, target_names=[\u001b[33m\"\u001b[39m\u001b[33mNegative\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPositive\u001b[39m\u001b[33m\"\u001b[39m], digits=\u001b[32m4\u001b[39m\n\u001b[32m     16\u001b[39m         )\n\u001b[32m     17\u001b[39m     )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Multi-label confusion matrices\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== CONFUSION MATRICES ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "# Generate detailed classification report\n",
    "y_true = np.array(y_test)\n",
    "y_pred = pred_labels\n",
    "\n",
    "print(\"=== DETAILED CLASSIFICATION REPORT ===\")\n",
    "target_names = [\"is_spam\", \"is_advertisement\", \"is_rant_without_visit\"]\n",
    "\n",
    "# Individual classification reports for each label\n",
    "for i, label_name in enumerate(target_names):\n",
    "    print(f\"\\n{label_name.upper()} Classification Report:\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_true[:, i], y_pred[:, i], target_names=[\"Negative\", \"Positive\"], digits=4\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Multi-label confusion matrices\n",
    "print(\"\\n=== CONFUSION MATRICES ===\")\n",
    "cm_multilabel = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "for i, label_name in enumerate(target_names):\n",
    "    print(f\"\\n{label_name.upper()} Confusion Matrix:\")\n",
    "    tn, fp, fn, tp = cm_multilabel[i].ravel()\n",
    "    print(f\"True Negatives:  {tn:4d}   False Positives: {fp:4d}\")\n",
    "    print(f\"False Negatives: {fn:4d}   True Positives:  {tp:4d}\")\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    print(f\"Specificity: {specificity:.4f}   Sensitivity: {sensitivity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62130529",
   "metadata": {},
   "source": [
    "## 12. Model Summary and Predictions Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8971cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_quality(\n",
    "    text,\n",
    "    business_name=\"Unknown\",\n",
    "    category=\"General\",\n",
    "    rating=3,\n",
    "    avg_rating=3.5,\n",
    "    num_reviews=50,\n",
    "    price_level=1,\n",
    "    has_pics=False,\n",
    "):\n",
    "    \"\"\"Predict review quality labels for a single review\"\"\"\n",
    "\n",
    "    # Prepare combined text\n",
    "    combined_text = (\n",
    "        f\"Review: {text} \"\n",
    "        f\"Business: {business_name} \"\n",
    "        f\"Category: {category} \"\n",
    "        f\"Rating: {rating}/5 \"\n",
    "        f\"Avg Rating: {avg_rating}/5 \"\n",
    "        f\"Reviews: {num_reviews} \"\n",
    "        f\"Price: {price_level} \"\n",
    "        f\"Has Photos: {has_pics}\"\n",
    "    )\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        combined_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "    ).to(device)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.sigmoid(outputs.logits)\n",
    "\n",
    "    # Convert to predictions\n",
    "    probs = predictions.cpu().numpy()[0]\n",
    "    labels = (probs > 0.5).astype(int)\n",
    "\n",
    "    results = {\n",
    "        \"is_spam\": {\"prediction\": bool(labels[0]), \"confidence\": float(probs[0])},\n",
    "        \"is_advertisement\": {\n",
    "            \"prediction\": bool(labels[1]),\n",
    "            \"confidence\": float(probs[1]),\n",
    "        },\n",
    "        \"is_rant_without_visit\": {\n",
    "            \"prediction\": bool(labels[2]),\n",
    "            \"confidence\": float(probs[2]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test the prediction function\n",
    "print(\"=== TESTING PREDICTION FUNCTION ===\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"This place is absolutely amazing! Best food ever!\",\n",
    "        \"business_name\": \"Joe's Diner\",\n",
    "        \"category\": \"Restaurant\",\n",
    "        \"rating\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Check out our website www.example.com for special deals!\",\n",
    "        \"business_name\": \"Tech Store\",\n",
    "        \"category\": \"Technology\",\n",
    "        \"rating\": 4,\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Terrible service! This place should be shut down!\",\n",
    "        \"business_name\": \"Bad Restaurant\",\n",
    "        \"category\": \"Restaurant\",\n",
    "        \"rating\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"\\nTest Case {i+1}:\")\n",
    "    print(f\"Text: '{test_case['text']}'\")\n",
    "\n",
    "    result = predict_review_quality(**test_case)\n",
    "\n",
    "    print(\"Predictions:\")\n",
    "    for label, pred in result.items():\n",
    "        status = \"YES\" if pred[\"prediction\"] else \"NO\"\n",
    "        confidence = pred[\"confidence\"]\n",
    "        print(f\"  {label}: {status} (confidence: {confidence:.3f})\")\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING COMPLETE ===\")\n",
    "print(\"The model is now ready to predict review quality labels!\")\n",
    "print(\"Use the predict_review_quality() function for new predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
