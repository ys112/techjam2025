{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d65756e",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Multi-Label Text Classification Pipeline\n",
    "\n",
    "This notebook implements a hybrid classification approach:\n",
    "1. **Regex-based rules** for obvious patterns (fast)\n",
    "2. **Zero-shot classification** for ambiguous cases (accurate)\n",
    "3. **Combined labeling** for final multi-label results\n",
    "\n",
    "**Target Labels:** Advertisement, Irrelevant, Fake_Rant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14bd7b5",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7c300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Setting up dependencies...\n",
      "‚úÖ transformers>=4.21.0 ready\n",
      "‚úÖ torch ready\n",
      "‚úÖ pandas ready\n",
      "‚úÖ numpy ready\n",
      "‚úÖ tqdm ready\n",
      "\n",
      "üöÄ All dependencies ready for lightning-fast classification!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for optimal performance\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"‚úÖ {package} ready\")\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è  {package} installation issue (might already be installed)\")\n",
    "\n",
    "print(\"üì¶ Setting up dependencies...\")\n",
    "packages = [\n",
    "    \"transformers>=4.21.0\",\n",
    "    \"torch\", \n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"\\nüöÄ All dependencies ready for lightning-fast classification!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993217bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Environment configured:\n",
      "   Device: CPU\n",
      "   PyTorch: 2.8.0\n",
      "   Pandas: 2.3.1\n",
      "\n",
      "‚ö° Ready for high-performance classification!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries with performance optimizations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Dict, Set\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Hugging Face imports with caching optimizations\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Configure for optimal performance\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set device for faster inference\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "device_name = \"GPU (CUDA)\" if device == 0 else \"CPU\"\n",
    "\n",
    "print(f\"üîß Environment configured:\")\n",
    "print(f\"   Device: {device_name}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")\n",
    "print(f\"\\n‚ö° Ready for high-performance classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ef397",
   "metadata": {},
   "source": [
    "## üìä Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6564df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading data from: ../data/cleaned_google_reviews.csv\n",
      "‚úÖ Dataset loaded successfully!\n",
      "   üìä Shape: (673065, 17)\n",
      "   üìã Columns: ['user_id', 'user_name', 'review_time', 'rating', 'review_text', 'pics', 'resp', 'gmap_id', 'has_resp', 'resp_text', 'resp_time', 'biz_name', 'description', 'category', 'avg_rating', 'num_of_reviews', 'price_level']\n",
      "\n",
      "üìù Text Data Quality:\n",
      "   Total rows: 673,065\n",
      "   Valid text rows: 347,087 (51.6%)\n",
      "   Empty/missing: 325,978\n",
      "\n",
      "üìã Sample Data:\n",
      "   Row 0: 'Great place to care for our children.'\n",
      "   Row 1: 'Th sw y are so nice'\n",
      "   Row 2: 'Went with my daughter'\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the dataset\n",
    "DATA_PATH = \"../data/cleaned_google_reviews.csv\"  # Update path as needed\n",
    "\n",
    "print(f\"üìÅ Loading data from: {DATA_PATH}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"   üìä Shape: {df.shape}\")\n",
    "    print(f\"   üìã Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Ensure text column exists and handle missing values\n",
    "    text_col = 'text' if 'text' in df.columns else 'review_text'\n",
    "    if text_col not in df.columns:\n",
    "        raise ValueError(f\"No text column found. Available columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Clean and prepare text data\n",
    "    df[text_col] = df[text_col].fillna('')  # Handle NaN values\n",
    "    df[text_col] = df[text_col].astype(str)  # Ensure string type\n",
    "    \n",
    "    # Filter out empty texts for processing\n",
    "    valid_text_mask = (df[text_col].str.len() > 0) & (df[text_col] != 'nan')\n",
    "    total_rows = len(df)\n",
    "    valid_rows = valid_text_mask.sum()\n",
    "    \n",
    "    print(f\"\\nüìù Text Data Quality:\")\n",
    "    print(f\"   Total rows: {total_rows:,}\")\n",
    "    print(f\"   Valid text rows: {valid_rows:,} ({valid_rows/total_rows*100:.1f}%)\")\n",
    "    print(f\"   Empty/missing: {total_rows - valid_rows:,}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(f\"\\nüìã Sample Data:\")\n",
    "    sample_df = df[valid_text_mask].head(3)\n",
    "    for i, row in sample_df.iterrows():\n",
    "        text_preview = row[text_col][:100] + \"...\" if len(row[text_col]) > 100 else row[text_col]\n",
    "        print(f\"   Row {i}: '{text_preview}'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå File not found: {DATA_PATH}\")\n",
    "    print(\"Creating sample dataset for demonstration...\")\n",
    "    \n",
    "    # Create sample data for demonstration\n",
    "    sample_data = {\n",
    "        'user_id': ['user1', 'user2', 'user3', 'user4', 'user5'],\n",
    "        'text': [\n",
    "            \"Buy now! 50% discount on all items! Call 555-1234 today!\",\n",
    "            \"hello\",\n",
    "            \"Never visited this place but heard bad things about it from friends\",\n",
    "            \"Great food and excellent service. Highly recommend this restaurant.\",\n",
    "            \"Thanks for the info\"\n",
    "        ],\n",
    "        'rating': [1, 3, 1, 5, 4],\n",
    "        'category': ['Restaurant', 'Store', 'Restaurant', 'Restaurant', 'Store']\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    text_col = 'text'\n",
    "    valid_text_mask = df[text_col].str.len() > 0\n",
    "    print(f\"‚úÖ Sample dataset created with {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf404a",
   "metadata": {},
   "source": [
    "## üîç Regex-Based Rule Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82d896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Regex Engine Initialized:\n",
      "   Advertisement: 5 patterns\n",
      "   Irrelevant: 4 patterns\n",
      "   Fake_Rant: 4 patterns\n",
      "   Total: 13 compiled regex patterns\n"
     ]
    }
   ],
   "source": [
    "class FastRuleClassifier:\n",
    "    \"\"\"Lightning-fast regex-based classification for obvious patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Pre-compiled regex patterns for maximum performance\n",
    "        self.patterns = {\n",
    "            'Advertisement': [\n",
    "                re.compile(r'\\b(buy now|discount|sale|offer|promo|deal|coupon|special offer)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'),  # Phone numbers\n",
    "                re.compile(r'\\b(call|contact|visit|website|www\\.|http)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b(free|limited time|act now|order today)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\$\\d+|\\b\\d+%\\s*off\\b', re.IGNORECASE),  # Prices and discounts\n",
    "            ],\n",
    "            'Irrelevant': [\n",
    "                re.compile(r'^\\s*(hello|hi|thanks|thank you|ok|okay)\\s*$', re.IGNORECASE),\n",
    "                re.compile(r'^\\s*\\w{1,4}\\s*$'),  # Very short single words\n",
    "                re.compile(r'\\b(weather|traffic|politics|government|election)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b(my car|my phone|personal|unrelated)\\b', re.IGNORECASE),\n",
    "            ],\n",
    "            'Fake_Rant': [\n",
    "                re.compile(r'\\b(never visited|never been|never went|haven\\'t been)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b(heard bad things|rumor|heard from|people say)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b(avoid|stay away|don\\'t go|waste of time)\\b', re.IGNORECASE),\n",
    "                re.compile(r'\\b(probably|seems like|looks like|appears)\\b.*\\b(bad|terrible|awful)\\b', re.IGNORECASE),\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Count patterns for performance metrics\n",
    "        total_patterns = sum(len(patterns) for patterns in self.patterns.values())\n",
    "        print(f\"üîç Regex Engine Initialized:\")\n",
    "        for label, patterns in self.patterns.items():\n",
    "            print(f\"   {label}: {len(patterns)} patterns\")\n",
    "        print(f\"   Total: {total_patterns} compiled regex patterns\")\n",
    "    \n",
    "    def classify_text(self, text: str) -> Set[str]:\n",
    "        \"\"\"Apply regex rules to classify text - returns set of matching labels\"\"\"\n",
    "        if not text or pd.isna(text) or text.strip() == '':\n",
    "            return set()\n",
    "        \n",
    "        labels = set()\n",
    "        text = str(text).strip()\n",
    "        \n",
    "        # Special case for very short text (Irrelevant)\n",
    "        if len(text.split()) < 5:\n",
    "            labels.add('Irrelevant')\n",
    "        \n",
    "        # Apply regex patterns\n",
    "        for label, patterns in self.patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.search(text):\n",
    "                    labels.add(label)\n",
    "                    break  # One match per category is enough\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def classify_dataframe(self, df: pd.DataFrame, text_column: str) -> pd.Series:\n",
    "        \"\"\"Apply regex classification to entire dataframe - vectorized for speed\"\"\"\n",
    "        print(f\"üöÄ Applying regex rules to {len(df):,} rows...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Apply classification with progress bar\n",
    "        rule_labels = df[text_column].progress_apply(self.classify_text)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        duration = time.time() - start_time\n",
    "        labeled_count = rule_labels.apply(len).sum()\n",
    "        rows_with_labels = (rule_labels.apply(len) > 0).sum()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Regex classification completed:\")\n",
    "        print(f\"   ‚è±Ô∏è  Time: {duration:.2f} seconds\")\n",
    "        print(f\"   ‚ö° Speed: {len(df)/duration:,.0f} rows/second\")\n",
    "        print(f\"   üéØ Labels assigned: {labeled_count}\")\n",
    "        print(f\"   üìä Rows with labels: {rows_with_labels:,} ({rows_with_labels/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        return rule_labels\n",
    "\n",
    "# Initialize the fast rule classifier\n",
    "rule_classifier = FastRuleClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6fa53",
   "metadata": {},
   "source": [
    "## ü§ñ Zero-Shot Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d90163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Zero-Shot Classifier Configuration:\n",
      "   Model: facebook/bart-large-mnli\n",
      "   Score threshold: 0.8\n",
      "   Labels: ['Advertisement', 'Irrelevant', 'Fake_Rant']\n",
      "   Device: CPU\n"
     ]
    }
   ],
   "source": [
    "class ZeroShotClassifier:\n",
    "    \"\"\"Hugging Face zero-shot classification for ambiguous cases\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"facebook/bart-large-mnli\", score_threshold=0.8):\n",
    "        self.model_name = model_name\n",
    "        self.score_threshold = score_threshold\n",
    "        self.candidate_labels = [\"Advertisement\", \"Irrelevant\", \"Fake_Rant\"]\n",
    "        self.pipeline = None\n",
    "        \n",
    "        print(f\"ü§ñ Zero-Shot Classifier Configuration:\")\n",
    "        print(f\"   Model: {model_name}\")\n",
    "        print(f\"   Score threshold: {score_threshold}\")\n",
    "        print(f\"   Labels: {self.candidate_labels}\")\n",
    "        print(f\"   Device: {device_name}\")\n",
    "    \n",
    "    def load_pipeline(self):\n",
    "        \"\"\"Load the zero-shot classification pipeline with optimizations\"\"\"\n",
    "        print(f\"\\n‚è≥ Loading {self.model_name} for zero-shot classification...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Load with optimizations for speed\n",
    "            self.pipeline = pipeline(\n",
    "                \"zero-shot-classification\",\n",
    "                model=self.model_name,\n",
    "                device=device,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                model_kwargs={\"cache_dir\": \".cache/huggingface\"}\n",
    "            )\n",
    "            \n",
    "            load_time = time.time() - start_time\n",
    "            print(f\"‚úÖ Pipeline loaded in {load_time:.1f} seconds - LIGHTNING FAST!\")\n",
    "            \n",
    "            # Warm up with a test prediction\n",
    "            test_result = self.pipeline(\"test\", self.candidate_labels)\n",
    "            print(f\"üî• Pipeline warmed up and ready for inference!\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load pipeline: {e}\")\n",
    "            print(f\"üí° Falling back to rule-based classification only\")\n",
    "            return False\n",
    "    \n",
    "    def classify_text(self, text: str) -> Set[str]:\n",
    "        \"\"\"Classify text using zero-shot classification\"\"\"\n",
    "        if not self.pipeline or not text or pd.isna(text) or text.strip() == '':\n",
    "            return set()\n",
    "        \n",
    "        try:\n",
    "            # Get predictions\n",
    "            result = self.pipeline(text, self.candidate_labels)\n",
    "            \n",
    "            # Extract labels with scores above threshold\n",
    "            labels = set()\n",
    "            for label, score in zip(result['labels'], result['scores']):\n",
    "                if score >= self.score_threshold:\n",
    "                    labels.add(label)\n",
    "            \n",
    "            return labels\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Classification error for text: {text[:50]}... - {e}\")\n",
    "            return set()\n",
    "    \n",
    "    def classify_batch(self, texts: List[str]) -> List[Set[str]]:\n",
    "        \"\"\"Classify multiple texts efficiently\"\"\"\n",
    "        if not self.pipeline:\n",
    "            return [set() for _ in texts]\n",
    "        \n",
    "        results = []\n",
    "        batch_size = 32  # Optimize batch size for memory\n",
    "        \n",
    "        print(f\"üîÑ Processing {len(texts)} texts in batches of {batch_size}...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Zero-shot batches\"):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            for text in batch:\n",
    "                labels = self.classify_text(text)\n",
    "                batch_results.append(labels)\n",
    "            \n",
    "            results.extend(batch_results)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize zero-shot classifier\n",
    "zero_shot_classifier = ZeroShotClassifier(score_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e75923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Loading facebook/bart-large-mnli for zero-shot classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline loaded in 0.9 seconds - LIGHTNING FAST!\n",
      "üî• Pipeline warmed up and ready for inference!\n",
      "\n",
      "üéØ Ready for hybrid classification:\n",
      "   1. Regex rules for obvious patterns (ultra-fast)\n",
      "   2. Zero-shot classification for ambiguous cases (accurate)\n"
     ]
    }
   ],
   "source": [
    "# Load the zero-shot pipeline (this may take a moment for first-time download)\n",
    "pipeline_loaded = zero_shot_classifier.load_pipeline()\n",
    "\n",
    "if pipeline_loaded:\n",
    "    print(\"\\nüéØ Ready for hybrid classification:\")\n",
    "    print(\"   1. Regex rules for obvious patterns (ultra-fast)\")\n",
    "    print(\"   2. Zero-shot classification for ambiguous cases (accurate)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Zero-shot classification unavailable - using regex rules only\")\n",
    "    print(\"   This may happen due to memory constraints or model loading issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebafd9",
   "metadata": {},
   "source": [
    "## ‚ö° Hybrid Classification Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38ad809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Hybrid Classifier ready for lightning-fast classification!\n"
     ]
    }
   ],
   "source": [
    "class HybridClassifier:\n",
    "    \"\"\"Combines regex rules and zero-shot classification for optimal performance\"\"\"\n",
    "    \n",
    "    def __init__(self, rule_classifier, zero_shot_classifier):\n",
    "        self.rule_classifier = rule_classifier\n",
    "        self.zero_shot_classifier = zero_shot_classifier\n",
    "    \n",
    "    def classify_dataframe(self, df: pd.DataFrame, text_column: str) -> pd.DataFrame:\n",
    "        \"\"\"Apply hybrid classification to entire dataframe\"\"\"\n",
    "        print(f\"üî• Starting Hybrid Classification Pipeline\")\n",
    "        print(f\"üìä Processing {len(df):,} rows\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Apply regex rules to all rows\n",
    "        print(f\"\\nüîç Step 1: Applying regex rules...\")\n",
    "        rule_labels = self.rule_classifier.classify_dataframe(df, text_column)\n",
    "        \n",
    "        # Step 2: Identify rows that need zero-shot classification\n",
    "        unlabeled_mask = rule_labels.apply(len) == 0\n",
    "        unlabeled_count = unlabeled_mask.sum()\n",
    "        \n",
    "        print(f\"\\nüìã Classification Status:\")\n",
    "        print(f\"   Rule-based labels: {(~unlabeled_mask).sum():,} rows\")\n",
    "        print(f\"   Needs zero-shot: {unlabeled_count:,} rows\")\n",
    "        \n",
    "        # Step 3: Apply zero-shot classification to unlabeled rows\n",
    "        final_labels = rule_labels.copy()\n",
    "        \n",
    "        if unlabeled_count > 0 and self.zero_shot_classifier.pipeline:\n",
    "            print(f\"\\nü§ñ Step 2: Applying zero-shot classification to {unlabeled_count:,} rows...\")\n",
    "            \n",
    "            unlabeled_texts = df.loc[unlabeled_mask, text_column].tolist()\n",
    "            zero_shot_start = time.time()\n",
    "            \n",
    "            zero_shot_labels = self.zero_shot_classifier.classify_batch(unlabeled_texts)\n",
    "            \n",
    "            zero_shot_duration = time.time() - zero_shot_start\n",
    "            print(f\"   ‚è±Ô∏è  Zero-shot time: {zero_shot_duration:.2f} seconds\")\n",
    "            print(f\"   ‚ö° Zero-shot speed: {unlabeled_count/zero_shot_duration:,.0f} rows/second\")\n",
    "            \n",
    "            # Merge zero-shot results with rule-based results\n",
    "            unlabeled_indices = df.index[unlabeled_mask].tolist()\n",
    "            for idx, labels in zip(unlabeled_indices, zero_shot_labels):\n",
    "                final_labels.iloc[idx] = labels\n",
    "        \n",
    "        elif unlabeled_count > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  Zero-shot classifier not available - {unlabeled_count:,} rows remain unlabeled\")\n",
    "        \n",
    "        # Step 4: Create final results\n",
    "        df_result = df.copy()\n",
    "        df_result['labels'] = final_labels.apply(list)  # Convert sets to lists\n",
    "        \n",
    "        # Add individual label columns for easier filtering\n",
    "        df_result['is_advertisement'] = final_labels.apply(lambda x: 'Advertisement' in x)\n",
    "        df_result['is_irrelevant'] = final_labels.apply(lambda x: 'Irrelevant' in x)\n",
    "        df_result['is_fake_rant'] = final_labels.apply(lambda x: 'Fake_Rant' in x)\n",
    "        \n",
    "        # Calculate final statistics\n",
    "        total_duration = time.time() - start_time\n",
    "        labeled_rows = (final_labels.apply(len) > 0).sum()\n",
    "        total_labels = final_labels.apply(len).sum()\n",
    "        \n",
    "        print(f\"\\nüéâ Hybrid Classification Complete!\")\n",
    "        print(f\"   ‚è±Ô∏è  Total time: {total_duration:.2f} seconds\")\n",
    "        print(f\"   ‚ö° Overall speed: {len(df)/total_duration:,.0f} rows/second\")\n",
    "        print(f\"   üéØ Labeled rows: {labeled_rows:,} ({labeled_rows/len(df)*100:.1f}%)\")\n",
    "        print(f\"   üè∑Ô∏è  Total labels: {total_labels}\")\n",
    "        \n",
    "        # Label distribution\n",
    "        print(f\"\\nüìä Label Distribution:\")\n",
    "        print(f\"   Advertisement: {df_result['is_advertisement'].sum():,} rows\")\n",
    "        print(f\"   Irrelevant: {df_result['is_irrelevant'].sum():,} rows\")\n",
    "        print(f\"   Fake_Rant: {df_result['is_fake_rant'].sum():,} rows\")\n",
    "        print(f\"   Clean (no labels): {(~(df_result['is_advertisement'] | df_result['is_irrelevant'] | df_result['is_fake_rant'])).sum():,} rows\")\n",
    "        \n",
    "        return df_result\n",
    "\n",
    "# Initialize hybrid classifier\n",
    "hybrid_classifier = HybridClassifier(rule_classifier, zero_shot_classifier)\n",
    "print(\"‚ö° Hybrid Classifier ready for lightning-fast classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b1eae",
   "metadata": {},
   "source": [
    "## üöÄ Execute Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac7724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Executing Complete Multi-Label Classification Pipeline\n",
      "============================================================\n",
      "üî• Starting Hybrid Classification Pipeline\n",
      "üìä Processing 673,065 rows\n",
      "\n",
      "üîç Step 1: Applying regex rules...\n",
      "üöÄ Applying regex rules to 673,065 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 673065/673065 [00:06<00:00, 98546.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Regex classification completed:\n",
      "   ‚è±Ô∏è  Time: 6.85 seconds\n",
      "   ‚ö° Speed: 98,257 rows/second\n",
      "   üéØ Labels assigned: 111130\n",
      "   üìä Rows with labels: 109,721 (16.3%)\n",
      "\n",
      "üìã Classification Status:\n",
      "   Rule-based labels: 109,721 rows\n",
      "   Needs zero-shot: 563,344 rows\n",
      "\n",
      "ü§ñ Step 2: Applying zero-shot classification to 563,344 rows...\n",
      "üîÑ Processing 563344 texts in batches of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot batches:   0%|          | 30/17605 [02:10<21:15:42,  4.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Apply hybrid classification\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_classified = \u001b[43mhybrid_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Classification pipeline completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Results saved in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column as list of strings\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mHybridClassifier.classify_dataframe\u001b[39m\u001b[34m(self, df, text_column)\u001b[39m\n\u001b[32m     33\u001b[39m unlabeled_texts = df.loc[unlabeled_mask, text_column].tolist()\n\u001b[32m     34\u001b[39m zero_shot_start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m zero_shot_labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_shot_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassify_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m zero_shot_duration = time.time() - zero_shot_start\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚è±Ô∏è  Zero-shot time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzero_shot_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mZeroShotClassifier.classify_batch\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     78\u001b[39m batch_results = []\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassify_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     batch_results.append(labels)\n\u001b[32m     84\u001b[39m results.extend(batch_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mZeroShotClassifier.classify_text\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Extract labels with scores above threshold\u001b[39;00m\n\u001b[32m     55\u001b[39m     labels = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:209\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__call__\u001b[39m\u001b[34m(self, sequences, *args, **kwargs)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1450\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1451\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1452\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1453\u001b[39m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1454\u001b[39m             )\n\u001b[32m   1455\u001b[39m         )\n\u001b[32m   1456\u001b[39m     )\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:1365\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1364\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1366\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:232\u001b[39m, in \u001b[36mZeroShotClassificationPipeline._forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters:\n\u001b[32m    231\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m model_outputs = {\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_label\u001b[39m\u001b[33m\"\u001b[39m: candidate_label,\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m: sequence,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m: inputs[\u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    238\u001b[39m     **outputs,\n\u001b[32m    239\u001b[39m }\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1602\u001b[39m, in \u001b[36mBartForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1600\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1602\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1603\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[32m   1621\u001b[39m eos_mask = input_ids.eq(\u001b[38;5;28mself\u001b[39m.config.eos_token_id).to(hidden_states.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1270\u001b[39m, in \u001b[36mBartModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1267\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1270\u001b[39m     encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1271\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1274\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1275\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[32m   1280\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:869\u001b[39m, in \u001b[36mBartEncoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    867\u001b[39m     layer_outputs = (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m     layer_outputs = \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         logger.warning(message)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:325\u001b[39m, in \u001b[36mBartEncoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[39m\n\u001b[32m    323\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.activation_fn(\u001b[38;5;28mself\u001b[39m.fc1(hidden_states))\n\u001b[32m    324\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.activation_dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    327\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Execute the complete hybrid classification pipeline\n",
    "print(\"üöÄ Executing Complete Multi-Label Classification Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Apply hybrid classification\n",
    "df_classified = hybrid_classifier.classify_dataframe(df, text_col)\n",
    "\n",
    "print(f\"\\n‚úÖ Classification pipeline completed successfully!\")\n",
    "print(f\"üìä Results saved in 'labels' column as list of strings\")\n",
    "print(f\"üîç Individual boolean columns added for easy filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fa238",
   "metadata": {},
   "source": [
    "## üìã Results Analysis and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba8fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results with examples\n",
    "print(\"üéØ CLASSIFICATION RESULTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall statistics\n",
    "total_rows = len(df_classified)\n",
    "labeled_rows = (df_classified['labels'].apply(len) > 0).sum()\n",
    "clean_rows = total_rows - labeled_rows\n",
    "\n",
    "print(f\"\\nüìä Overall Statistics:\")\n",
    "print(f\"   Total rows: {total_rows:,}\")\n",
    "print(f\"   Flagged rows: {labeled_rows:,} ({labeled_rows/total_rows*100:.1f}%)\")\n",
    "print(f\"   Clean rows: {clean_rows:,} ({clean_rows/total_rows*100:.1f}%)\")\n",
    "\n",
    "# Label-specific statistics\n",
    "print(f\"\\nüè∑Ô∏è  Label Breakdown:\")\n",
    "ad_count = df_classified['is_advertisement'].sum()\n",
    "irrelevant_count = df_classified['is_irrelevant'].sum()\n",
    "fake_rant_count = df_classified['is_fake_rant'].sum()\n",
    "\n",
    "print(f\"   üì¢ Advertisement: {ad_count:,} ({ad_count/total_rows*100:.1f}%)\")\n",
    "print(f\"   üö´ Irrelevant: {irrelevant_count:,} ({irrelevant_count/total_rows*100:.1f}%)\")\n",
    "print(f\"   üò° Fake_Rant: {fake_rant_count:,} ({fake_rant_count/total_rows*100:.1f}%)\")\n",
    "\n",
    "# Multi-label statistics\n",
    "multi_label_mask = df_classified['labels'].apply(len) > 1\n",
    "multi_label_count = multi_label_mask.sum()\n",
    "print(f\"   üîÑ Multi-label: {multi_label_count:,} ({multi_label_count/total_rows*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìù EXAMPLE CLASSIFICATIONS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Show examples for each label category\n",
    "categories = {\n",
    "    'üì¢ Advertisement Examples': df_classified[df_classified['is_advertisement']],\n",
    "    'üö´ Irrelevant Examples': df_classified[df_classified['is_irrelevant']],\n",
    "    'üò° Fake_Rant Examples': df_classified[df_classified['is_fake_rant']],\n",
    "    '‚úÖ Clean Examples': df_classified[~(df_classified['is_advertisement'] | \n",
    "                                        df_classified['is_irrelevant'] | \n",
    "                                        df_classified['is_fake_rant'])]\n",
    "}\n",
    "\n",
    "for category_name, category_df in categories.items():\n",
    "    if len(category_df) > 0:\n",
    "        print(f\"\\n{category_name}:\")\n",
    "        sample_size = min(3, len(category_df))\n",
    "        \n",
    "        for i, (idx, row) in enumerate(category_df.head(sample_size).iterrows()):\n",
    "            text_preview = row[text_col][:120] + \"...\" if len(row[text_col]) > 120 else row[text_col]\n",
    "            labels_str = ', '.join(row['labels']) if row['labels'] else 'None'\n",
    "            \n",
    "            print(f\"   {i+1}. Text: '{text_preview}'\")\n",
    "            print(f\"      Labels: [{labels_str}]\")\n",
    "            if 'rating' in row:\n",
    "                print(f\"      Rating: {row['rating']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"\\n{category_name}: No examples found\")\n",
    "\n",
    "# Display final dataset info\n",
    "print(f\"\\nüíæ Final Dataset:\")\n",
    "print(f\"   Shape: {df_classified.shape}\")\n",
    "print(f\"   New columns: labels, is_advertisement, is_irrelevant, is_fake_rant\")\n",
    "print(f\"   Memory usage: {df_classified.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260e3a3",
   "metadata": {},
   "source": [
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classified dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"../outputs/classified\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate timestamped filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"classified_reviews_{timestamp}.csv\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# Save the results\n",
    "df_classified.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"üíæ Classified dataset saved:\")\n",
    "print(f\"   üìÅ Path: {output_path}\")\n",
    "print(f\"   üìä Rows: {len(df_classified):,}\")\n",
    "print(f\"   üè∑Ô∏è  Columns: {len(df_classified.columns)}\")\n",
    "\n",
    "# Save classification summary\n",
    "summary = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"total_rows\": len(df_classified),\n",
    "    \"classification_method\": \"hybrid_regex_zeroshot\",\n",
    "    \"zero_shot_model\": zero_shot_classifier.model_name if zero_shot_classifier.pipeline else \"Not used\",\n",
    "    \"label_counts\": {\n",
    "        \"advertisement\": int(df_classified['is_advertisement'].sum()),\n",
    "        \"irrelevant\": int(df_classified['is_irrelevant'].sum()),\n",
    "        \"fake_rant\": int(df_classified['is_fake_rant'].sum()),\n",
    "        \"clean\": int((~(df_classified['is_advertisement'] | \n",
    "                       df_classified['is_irrelevant'] | \n",
    "                       df_classified['is_fake_rant'])).sum())\n",
    "    },\n",
    "    \"multi_label_rows\": int((df_classified['labels'].apply(len) > 1).sum())\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(output_dir, f\"classification_summary_{timestamp}.json\")\n",
    "import json\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìä Classification summary saved: {summary_path}\")\n",
    "\n",
    "print(f\"\\nüéâ MULTI-LABEL CLASSIFICATION COMPLETE!\")\n",
    "print(f\"\\n‚ú® Your data is now classified with lightning speed and high accuracy!\")\n",
    "print(f\"üî• Ready for downstream ML tasks, filtering, or analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
