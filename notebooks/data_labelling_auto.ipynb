{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53179e7d",
   "metadata": {},
   "source": [
    "# 🏷️ Automated Data Labeling with Label Studio\n",
    "\n",
    "This notebook implements a complete workflow for automated data labeling:\n",
    "\n",
    "1. **📊 Data Sampling**: Read data and sample 10% for manual labeling\n",
    "2. **🏷️ Manual Labeling**: Send sample to Label Studio for multi-label classification\n",
    "3. **🤖 Rule Generation**: Extract patterns from labeled data\n",
    "4. **⚡ Auto Labeling**: Apply rules to label the entire dataset\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dff6d0",
   "metadata": {},
   "source": [
    "## 📦 1. Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e08028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Installing required packages...\n",
      "Requirement already satisfied: label-studio-sdk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.18)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (11.3.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (1.4.4)\n",
      "Requirement already satisfied: datamodel-code-generator==0.26.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (0.26.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (0.28.1)\n",
      "Requirement already satisfied: ijson>=3.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (3.4.0)\n",
      "Requirement already satisfied: jsf<0.12.0,>=0.11.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=4.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (4.25.1)\n",
      "Requirement already satisfied: lxml>=4.2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (5.4.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (3.9.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.26.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (1.26.4)\n",
      "Requirement already satisfied: opencv-python<5.0.0,>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (4.11.0.86)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (2.3.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (2.33.2)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (2.10.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (2.32.4)\n",
      "Requirement already satisfied: requests-mock==1.12.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (1.12.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from label-studio-sdk) (4.12.2)\n",
      "Requirement already satisfied: ujson>=5.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (5.11.0)\n",
      "Requirement already satisfied: xmljson==0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from label-studio-sdk) (0.2.1)\n",
      "Requirement already satisfied: argcomplete<4.0,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (3.6.2)\n",
      "Requirement already satisfied: black>=19.10b0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (25.1.0)\n",
      "Requirement already satisfied: genson<2.0,>=1.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (1.3.0)\n",
      "Requirement already satisfied: inflect<6.0,>=4.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (5.6.2)\n",
      "Requirement already satisfied: isort<6.0,>=4.3.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (5.13.2)\n",
      "Requirement already satisfied: jinja2<4.0,>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (3.1.6)\n",
      "Requirement already satisfied: packaging in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (25.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2<4.0,>=2.10.1->datamodel-code-generator==0.26.1->label-studio-sdk) (3.0.2)\n",
      "Requirement already satisfied: faker>=15.3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk) (37.6.0)\n",
      "Requirement already satisfied: rstr>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk) (3.2.2)\n",
      "Requirement already satisfied: smart-open>=6.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk) (7.3.0.post1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=1.9.2->label-studio-sdk) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic>=1.9.2->label-studio-sdk) (0.4.1)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk) (2.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.22.0->label-studio-sdk) (2025.7.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk) (4.3.8)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from email-validator>=2.0.0->pydantic[email]!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.11\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk) (2.7.0)\n",
      "Requirement already satisfied: tzdata in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from faker>=15.3.4->jsf<0.12.0,>=0.11.2->label-studio-sdk) (2025.2)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx>=0.21.2->label-studio-sdk) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx>=0.21.2->label-studio-sdk) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->label-studio-sdk) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonschema>=4.23.0->label-studio-sdk) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from pandas>=0.24.0->label-studio-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24.0->label-studio-sdk) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->label-studio-sdk) (1.17.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open>=6.3.0->smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk) (1.17.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio->httpx>=0.21.2->label-studio-sdk) (1.3.1)\n",
      "✅ label-studio-sdk installed successfully\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lunlun/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "✅ pandas installed successfully\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.4)\n",
      "✅ numpy installed successfully\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests) (2025.7.14)\n",
      "✅ requests installed successfully\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "✅ scikit-learn installed successfully\n",
      "\n",
      "🎉 All packages ready!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} installed successfully\")\n",
    "    except:\n",
    "        print(f\"⚠️  {package} installation failed, might already be installed\")\n",
    "\n",
    "\n",
    "# Install Label Studio SDK and other dependencies\n",
    "packages = [\"label-studio-sdk\", \"pandas\", \"numpy\", \"requests\", \"scikit-learn\"]\n",
    "\n",
    "print(\"📦 Installing required packages...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n🎉 All packages ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f34108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "from label_studio_sdk import Client\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd286c",
   "metadata": {},
   "source": [
    "## 📊 2. Data Loading and Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2abdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Loading data from: ../data/cleaned_google_reviews.csv\n",
      "🎲 Sampling 10.0% of data for manual labeling\n",
      "\n",
      "📊 Dataset Overview:\n",
      "   Total rows: 347,087\n",
      "   Columns: ['user_id', 'user_name', 'review_time', 'rating', 'review_text', 'pics', 'resp', 'gmap_id', 'has_resp', 'resp_text', 'resp_time', 'biz_name', 'description', 'category', 'avg_rating', 'num_of_reviews', 'price_level']\n",
      "   Memory usage: 45.0 MB\n",
      "\n",
      "🎯 Sampling Results:\n",
      "   Sample size: 34,708 rows (10.0%)\n",
      "   Remaining for auto-labeling: 312,379 rows\n",
      "\n",
      "📝 Sample Data Preview:\n",
      "\n",
      "   Row 1:\n",
      "   📝 Review: 'Love the campground. Staff has gone above and beyond. Have stayed for two months. Sites are paved, a...'\n",
      "   ⭐ Rating: 5\n",
      "   🏷️  Category: ['Campground']\n",
      "\n",
      "   Row 2:\n",
      "   📝 Review: '1st time evee.give McDonald's a 5 star thanks to guy named Tyler working front counter. Had the best...'\n",
      "   ⭐ Rating: 5\n",
      "   🏷️  Category: ['Fast food restaurant', 'Breakfast restaurant', 'Coffee shop', 'Hamburger restaurant', 'Restaurant', 'Sandwich shop']\n",
      "\n",
      "   Row 3:\n",
      "   📝 Review: 'The burgers are fantastic!...'\n",
      "   ⭐ Rating: 5\n",
      "   🏷️  Category: ['Bar & grill']\n"
     ]
    }
   ],
   "source": [
    "# Configure data path and sampling parameters\n",
    "DATA_PATH = \"../data/cleaned_google_reviews.csv\"\n",
    "SAMPLE_PERCENTAGE = 0.1  # 10% sampling\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"📁 Loading data from: {DATA_PATH}\")\n",
    "print(f\"🎲 Sampling {SAMPLE_PERCENTAGE*100}% of data for manual labeling\")\n",
    "\n",
    "# Load the complete dataset\n",
    "df_full = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Clean and prepare data\n",
    "df_full = df_full[df_full[\"review_text\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n📊 Dataset Overview:\")\n",
    "print(f\"   Total rows: {len(df_full):,}\")\n",
    "print(f\"   Columns: {df_full.columns.tolist()}\")\n",
    "print(f\"   Memory usage: {df_full.memory_usage().sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Sample data for manual labeling\n",
    "sample_size = int(len(df_full) * SAMPLE_PERCENTAGE)\n",
    "df_sample = df_full.sample(n=sample_size, random_state=RANDOM_STATE).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 Sampling Results:\")\n",
    "print(f\"   Sample size: {len(df_sample):,} rows ({SAMPLE_PERCENTAGE*100}%)\")\n",
    "print(f\"   Remaining for auto-labeling: {len(df_full) - len(df_sample):,} rows\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\n📝 Sample Data Preview:\")\n",
    "display_cols = (\n",
    "    [\"review_text\", \"rating\", \"category\"]\n",
    "    if \"category\" in df_sample.columns\n",
    "    else [\"review_text\", \"rating\"]\n",
    ")\n",
    "for i, row in df_sample.head(3).iterrows():\n",
    "    print(f\"\\n   Row {i+1}:\")\n",
    "    print(f\"   📝 Review: '{row['review_text'][:100]}...'\")\n",
    "    print(f\"   ⭐ Rating: {row.get('rating', 'N/A')}\")\n",
    "    if \"category\" in row:\n",
    "        print(f\"   🏷️  Category: {row.get('category', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97be86b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review_time</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>has_resp</th>\n",
       "      <th>resp_text</th>\n",
       "      <th>resp_time</th>\n",
       "      <th>biz_name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103563353519118155776</td>\n",
       "      <td>Peri Gray</td>\n",
       "      <td>2018-01-16 17:11:15.780000+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Great place to care for our children.</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x532af45db8f30779:0xd9be9359f1e56178</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRST WIC Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101824980797027237888</td>\n",
       "      <td>Suzy Berndt</td>\n",
       "      <td>2018-07-30 03:45:50.314000+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Th sw y are so nice</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x532af45db8f30779:0xd9be9359f1e56178</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRST WIC Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108711640480272777216</td>\n",
       "      <td>Rosemary Red Legs</td>\n",
       "      <td>2018-07-07 13:11:33.932000+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Went with my daughter</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x532af45db8f30779:0xd9be9359f1e56178</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRST WIC Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111135746986864017408</td>\n",
       "      <td>hypnotherapycw</td>\n",
       "      <td>2017-02-18 23:59:28.190000+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>Julie and the crew are AMAZING. DONATE DONATE ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x532af4588c5f80b1:0x19574964b8ecd9a0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cheyenne River Youth Project</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Youth social services organization']</td>\n",
       "      <td>4.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108987444312280645632</td>\n",
       "      <td>C J Blue Coat</td>\n",
       "      <td>2016-02-25 10:10:42.607000+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>They dont have any activities for youth. If so...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x532af4588c5f80b1:0x19574964b8ecd9a0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cheyenne River Youth Project</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Youth social services organization']</td>\n",
       "      <td>4.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id          user_name                       review_time  \\\n",
       "0  103563353519118155776          Peri Gray  2018-01-16 17:11:15.780000+00:00   \n",
       "1  101824980797027237888        Suzy Berndt  2018-07-30 03:45:50.314000+00:00   \n",
       "2  108711640480272777216  Rosemary Red Legs  2018-07-07 13:11:33.932000+00:00   \n",
       "3  111135746986864017408     hypnotherapycw  2017-02-18 23:59:28.190000+00:00   \n",
       "4  108987444312280645632      C J Blue Coat  2016-02-25 10:10:42.607000+00:00   \n",
       "\n",
       "  rating                                        review_text   pics resp  \\\n",
       "0      5              Great place to care for our children.  False  NaN   \n",
       "1      5                                Th sw y are so nice  False  NaN   \n",
       "2      5                              Went with my daughter  False  NaN   \n",
       "3      5  Julie and the crew are AMAZING. DONATE DONATE ...  False  NaN   \n",
       "4      2  They dont have any activities for youth. If so...  False  NaN   \n",
       "\n",
       "                                 gmap_id has_resp resp_text resp_time  \\\n",
       "0  0x532af45db8f30779:0xd9be9359f1e56178    False       NaN       NaN   \n",
       "1  0x532af45db8f30779:0xd9be9359f1e56178    False       NaN       NaN   \n",
       "2  0x532af45db8f30779:0xd9be9359f1e56178    False       NaN       NaN   \n",
       "3  0x532af4588c5f80b1:0x19574964b8ecd9a0    False       NaN       NaN   \n",
       "4  0x532af4588c5f80b1:0x19574964b8ecd9a0    False       NaN       NaN   \n",
       "\n",
       "                       biz_name description  \\\n",
       "0               CRST WIC Office         NaN   \n",
       "1               CRST WIC Office         NaN   \n",
       "2               CRST WIC Office         NaN   \n",
       "3  Cheyenne River Youth Project         NaN   \n",
       "4  Cheyenne River Youth Project         NaN   \n",
       "\n",
       "                                 category  avg_rating  num_of_reviews  \\\n",
       "0                                     NaN         4.7             8.0   \n",
       "1                                     NaN         4.7             8.0   \n",
       "2                                     NaN         4.7             8.0   \n",
       "3  ['Youth social services organization']         4.5            35.0   \n",
       "4  ['Youth social services organization']         4.5            35.0   \n",
       "\n",
       "   price_level  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919aa127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a08ff7",
   "metadata": {},
   "source": [
    "## 🔧 3. Label Studio Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430b0744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Label Studio Configuration:\n",
      "   URL: http://localhost:8080\n",
      "   Labels: Advertisement, Irrelevant, Fake_Rant\n",
      "   Type: Multi-label classification\n",
      "\n",
      "⚠️  Make sure Label Studio is running: label-studio start\n"
     ]
    }
   ],
   "source": [
    "# Label Studio Configuration\n",
    "LABEL_STUDIO_URL = \"http://localhost:8080\"\n",
    "API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoicmVmcmVzaCIsImV4cCI6ODA2MzY1MTU1NCwiaWF0IjoxNzU2NDUxNTU0LCJqdGkiOiI3NWFhOGY5NjQwZDU0NmVjOTJhZGIxOTljMzBmYjk3ZSIsInVzZXJfaWQiOiIxIn0.DiyYKh46ZGAewSsq8Fe82JfBpVJllyL_-s2P0UxWLp4\"  # Replace with your actual API key\n",
    "\n",
    "# Multi-label classification configuration\n",
    "LABEL_CONFIG = \"\"\"\n",
    "<View>\n",
    "  <Header value=\"Review Classification Task\"/>\n",
    "  \n",
    "  <Text name=\"review\" value=\"$review_text\" granularity=\"word\"/>\n",
    "  \n",
    "  <Header value=\"Select all applicable labels:\"/>\n",
    "  <Choices name=\"classification\" toName=\"review\" choice=\"multiple\">\n",
    "    <Choice value=\"Advertisement\" hint=\"Contains promotional content, contact info, or marketing language\"/>\n",
    "    <Choice value=\"Irrelevant\" hint=\"Off-topic content not related to the business/service\"/>\n",
    "    <Choice value=\"Fake_Rant\" hint=\"Complaints from users who likely never visited the business\"/>\n",
    "  </Choices>\n",
    "  \n",
    "  <Header value=\"Additional Context:\"/>\n",
    "  <Text name=\"metadata\" value=\"$metadata\" granularity=\"word\"/>\n",
    "</View>\n",
    "\"\"\"\n",
    "\n",
    "print(\"🔧 Label Studio Configuration:\")\n",
    "print(f\"   URL: {LABEL_STUDIO_URL}\")\n",
    "print(f\"   Labels: Advertisement, Irrelevant, Fake_Rant\")\n",
    "print(f\"   Type: Multi-label classification\")\n",
    "print(\"\\n⚠️  Make sure Label Studio is running: label-studio start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3bcb3",
   "metadata": {},
   "source": [
    "## 🏷️ 4. Label Studio Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf7e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Label Studio Manager initialized\n"
     ]
    }
   ],
   "source": [
    "class LabelStudioManager:\n",
    "    \"\"\"Manager class for Label Studio operations\"\"\"\n",
    "\n",
    "    def __init__(self, url: str, api_key: str):\n",
    "        self.url = url\n",
    "        self.api_key = api_key\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Token {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        self.client = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Test connection to Label Studio\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.url}/api/version\", headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✅ Connected to Label Studio: {response.json()}\")\n",
    "                self.client = Client(url=self.url, api_key=self.api_key)\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"❌ Connection failed: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Connection error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def create_project(self, title: str, label_config: str) -> int:\n",
    "        \"\"\"Create a new Label Studio project\"\"\"\n",
    "        payload = {\n",
    "            \"title\": title,\n",
    "            \"label_config\": label_config,\n",
    "            \"expert_instruction\": \"Label reviews with applicable categories: Advertisement, Irrelevant, or Fake_Rant\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            f\"{self.url}/api/projects/\", headers=self.headers, data=json.dumps(payload)\n",
    "        )\n",
    "\n",
    "        if response.status_code == 201:\n",
    "            project_id = response.json()[\"id\"]\n",
    "            print(f\"✅ Project created with ID: {project_id}\")\n",
    "            return project_id\n",
    "        else:\n",
    "            print(\n",
    "                f\"❌ Project creation failed: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "    def prepare_tasks(self, df: pd.DataFrame) -> List[Dict]:\n",
    "        \"\"\"Convert DataFrame to Label Studio task format\"\"\"\n",
    "        tasks = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            # Create metadata string from all non-text columns\n",
    "            metadata_fields = []\n",
    "            for col, val in row.items():\n",
    "                if col != \"review_text\" and pd.notna(val):\n",
    "                    metadata_fields.append(f\"{col}: {val}\")\n",
    "\n",
    "            metadata_str = \" | \".join(metadata_fields)\n",
    "\n",
    "            task = {\n",
    "                \"data\": {\n",
    "                    \"review_text\": str(row.get(\"review_text\", \"\")),\n",
    "                    \"metadata\": metadata_str,\n",
    "                    \"row_id\": idx,  # Keep track of original row\n",
    "                }\n",
    "            }\n",
    "            tasks.append(task)\n",
    "\n",
    "        print(f\"✅ Prepared {len(tasks)} tasks for labeling\")\n",
    "        return tasks\n",
    "\n",
    "    def import_tasks(self, project_id: int, tasks: List[Dict]) -> bool:\n",
    "        \"\"\"Import tasks to Label Studio project\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.url}/api/projects/{project_id}/import\",\n",
    "            headers=self.headers,\n",
    "            data=json.dumps(tasks),\n",
    "        )\n",
    "\n",
    "        if response.status_code in [200, 201]:\n",
    "            print(f\"✅ Successfully imported {len(tasks)} tasks\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Task import failed: {response.status_code} - {response.text}\")\n",
    "            return False\n",
    "\n",
    "    def get_annotations(self, project_id: int) -> List[Dict]:\n",
    "        \"\"\"Retrieve annotations from project\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"{self.url}/api/projects/{project_id}/export\",\n",
    "            headers=self.headers,\n",
    "            params={\"exportType\": \"JSON\"},\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            annotations = response.json()\n",
    "            print(f\"✅ Retrieved {len(annotations)} annotations\")\n",
    "            return annotations\n",
    "        else:\n",
    "            print(f\"❌ Failed to retrieve annotations: {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "# Initialize Label Studio Manager\n",
    "ls_manager = LabelStudioManager(LABEL_STUDIO_URL, API_KEY)\n",
    "print(\"🔧 Label Studio Manager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3786656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 Testing Label Studio connection...\n",
      "✅ Connected to Label Studio: {'release': '1.20.0', 'label-studio-os-package': {'version': '1.20.0', 'short_version': '1.20', 'latest_version_from_pypi': '1.20.0', 'latest_version_upload_time': '2025-07-01T07:29:54', 'current_version_is_outdated': False}, 'label-studio-os-backend': {'message': 'fix: FIT-306: Zooming out the page breaks audio rendering of the wavef ...', 'commit': 'fb90125beebf3f951d844194cb401cd22d8f18b9', 'date': '2025/06/27 07:31:54', 'branch': '', 'version': '1.20.0+0.gfb90125'}, 'label-studio-frontend': {'message': 'fix: FIT-306: Zooming out the page breaks audio rendering of the wavef ...', 'commit': 'fb9012', 'date': '2025-06-27T12:31:54.000Z', 'branch': 'develop'}, 'dm2': {'message': 'fix: FIT-306: Zooming out the page breaks audio rendering of the wavef ...', 'commit': 'fb9012', 'date': '2025-06-27T12:31:54.000Z', 'branch': 'develop'}, 'label-studio-converter': {'version': '1.0.18'}, 'edition': 'Community', 'lsf': {'message': 'fix: FIT-306: Zooming out the page breaks audio rendering of the wavef ...', 'commit': 'fb9012', 'date': '2025-06-27T12:31:54.000Z', 'branch': 'develop'}, 'backend': {'commit': 'fb9012'}}\n",
      "❌ Project creation failed: 401 - {\"id\":\"4d459daa-2f5d-42a7-bff3-5864e120eb9f\",\"status_code\":401,\"version\":\"1.20.0\",\"detail\":\"Invalid token.\",\"exc_info\":null}\n",
      "❌ Failed to create project\n"
     ]
    }
   ],
   "source": [
    "# Test connection and create project\n",
    "print(\"🔌 Testing Label Studio connection...\")\n",
    "\n",
    "if ls_manager.connect():\n",
    "    # Create project for manual labeling\n",
    "    project_title = f\"Review Classification - {time.strftime('%Y%m%d_%H%M%S')}\"\n",
    "    project_id = ls_manager.create_project(project_title, LABEL_CONFIG)\n",
    "\n",
    "    if project_id:\n",
    "        # Prepare and import sample tasks\n",
    "        print(f\"\\n📤 Preparing tasks for manual labeling...\")\n",
    "        tasks = ls_manager.prepare_tasks(df_sample)\n",
    "\n",
    "        if ls_manager.import_tasks(project_id, tasks):\n",
    "            print(f\"\\n🎉 Setup Complete!\")\n",
    "            print(f\"   Project ID: {project_id}\")\n",
    "            print(f\"   Tasks imported: {len(tasks)}\")\n",
    "            print(f\"   Access URL: {LABEL_STUDIO_URL}/projects/{project_id}\")\n",
    "            print(f\"\\n👉 Next Steps:\")\n",
    "            print(f\"   1. Go to Label Studio UI and label the sample data\")\n",
    "            print(f\"   2. Run the next cell to extract labeling rules\")\n",
    "            print(f\"   3. Apply rules to auto-label the full dataset\")\n",
    "        else:\n",
    "            print(\"❌ Failed to import tasks\")\n",
    "    else:\n",
    "        print(\"❌ Failed to create project\")\n",
    "else:\n",
    "    print(\"❌ Could not connect to Label Studio\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"   1. Make sure Label Studio is running: label-studio start\")\n",
    "    print(\"   2. Check if the URL is correct\")\n",
    "    print(\"   3. Verify your API key is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52e671",
   "metadata": {},
   "source": [
    "## 🤖 5. Extract Labeling Rules from Manual Annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15b40db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Rule Extractor initialized\n"
     ]
    }
   ],
   "source": [
    "class RuleExtractor:\n",
    "    \"\"\"Extract labeling rules from manually labeled data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rules = {\"Advertisement\": [], \"Irrelevant\": [], \"Fake_Rant\": []}\n",
    "\n",
    "    def extract_rules_from_annotations(self, annotations: List[Dict]) -> Dict:\n",
    "        \"\"\"Extract pattern-based rules from labeled data\"\"\"\n",
    "        labeled_data = {\"Advertisement\": [], \"Irrelevant\": [], \"Fake_Rant\": []}\n",
    "\n",
    "        # Process annotations to extract labeled examples\n",
    "        for annotation in annotations:\n",
    "            if \"annotations\" in annotation and len(annotation[\"annotations\"]) > 0:\n",
    "                review_text = annotation[\"data\"][\"review_text\"]\n",
    "                labels = annotation[\"annotations\"][0][\"result\"]\n",
    "\n",
    "                # Extract selected labels\n",
    "                selected_labels = []\n",
    "                for label in labels:\n",
    "                    if label[\"from_name\"] == \"classification\":\n",
    "                        selected_labels.extend(label[\"value\"][\"choices\"])\n",
    "\n",
    "                # Add to appropriate categories\n",
    "                for category in [\"Advertisement\", \"Irrelevant\", \"Fake_Rant\"]:\n",
    "                    if category in selected_labels:\n",
    "                        labeled_data[category].append(review_text.lower())\n",
    "\n",
    "        print(f\"📊 Labeled Data Distribution:\")\n",
    "        for category, texts in labeled_data.items():\n",
    "            print(f\"   {category}: {len(texts)} examples\")\n",
    "\n",
    "        # Extract keyword-based rules\n",
    "        self._extract_keyword_rules(labeled_data)\n",
    "\n",
    "        return self.rules\n",
    "\n",
    "    def _extract_keyword_rules(self, labeled_data: Dict[str, List[str]]):\n",
    "        \"\"\"Extract keyword patterns from labeled examples\"\"\"\n",
    "\n",
    "        # Advertisement patterns\n",
    "        ad_patterns = [\n",
    "            r\"\\b(call|phone|contact)\\b\",\n",
    "            r\"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b\",  # Phone numbers\n",
    "            r\"\\b(visit|website|www|http)\\b\",\n",
    "            r\"\\b(discount|sale|promo|deal|offer|coupon)\\b\",\n",
    "            r\"\\b(free|limited|special)\\b\",\n",
    "            r\"@\\w+\\.[a-z]+\",  # Email patterns\n",
    "        ]\n",
    "\n",
    "        # Irrelevant patterns\n",
    "        irrelevant_patterns = [\n",
    "            r\"\\b(weather|traffic|politics|government)\\b\",\n",
    "            r\"\\b(my car|my phone|my house)\\b\",\n",
    "            r\"\\b(news|television|movie|sports)\\b\",\n",
    "            r\"\\b(unrelated|off.topic|nothing to do)\\b\",\n",
    "        ]\n",
    "\n",
    "        # Fake rant patterns\n",
    "        fake_rant_patterns = [\n",
    "            r\"\\b(never been|never visited|never went)\\b\",\n",
    "            r\"\\b(heard|looks like|seems like|probably)\\b\",\n",
    "            r\"\\b(all these places|these types|hate these)\\b\",\n",
    "            r\"\\b(avoid|stay away|waste of time)\\b\",\n",
    "        ]\n",
    "\n",
    "        self.rules = {\n",
    "            \"Advertisement\": ad_patterns,\n",
    "            \"Irrelevant\": irrelevant_patterns,\n",
    "            \"Fake_Rant\": fake_rant_patterns,\n",
    "        }\n",
    "\n",
    "        # Enhance rules based on actual labeled data\n",
    "        self._enhance_rules_from_examples(labeled_data)\n",
    "\n",
    "        print(f\"\\n🔍 Extracted Rules:\")\n",
    "        for category, patterns in self.rules.items():\n",
    "            print(f\"   {category}: {len(patterns)} patterns\")\n",
    "\n",
    "    def _enhance_rules_from_examples(self, labeled_data: Dict[str, List[str]]):\n",
    "        \"\"\"Enhance rules by analyzing common words in labeled examples\"\"\"\n",
    "        from collections import Counter\n",
    "        import re\n",
    "\n",
    "        for category, texts in labeled_data.items():\n",
    "            if len(texts) > 0:\n",
    "                # Extract common words from this category\n",
    "                all_words = []\n",
    "                for text in texts:\n",
    "                    words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "                    all_words.extend(words)\n",
    "\n",
    "                # Find most common words (excluding common stop words)\n",
    "                stop_words = {\n",
    "                    \"the\",\n",
    "                    \"a\",\n",
    "                    \"an\",\n",
    "                    \"and\",\n",
    "                    \"or\",\n",
    "                    \"but\",\n",
    "                    \"in\",\n",
    "                    \"on\",\n",
    "                    \"at\",\n",
    "                    \"to\",\n",
    "                    \"for\",\n",
    "                    \"of\",\n",
    "                    \"with\",\n",
    "                    \"by\",\n",
    "                    \"is\",\n",
    "                    \"was\",\n",
    "                    \"are\",\n",
    "                    \"were\",\n",
    "                    \"be\",\n",
    "                    \"been\",\n",
    "                    \"have\",\n",
    "                    \"has\",\n",
    "                    \"had\",\n",
    "                    \"do\",\n",
    "                    \"does\",\n",
    "                    \"did\",\n",
    "                    \"will\",\n",
    "                    \"would\",\n",
    "                    \"could\",\n",
    "                    \"should\",\n",
    "                    \"this\",\n",
    "                    \"that\",\n",
    "                    \"they\",\n",
    "                    \"them\",\n",
    "                    \"their\",\n",
    "                }\n",
    "\n",
    "                word_counts = Counter(\n",
    "                    [w for w in all_words if len(w) > 3 and w not in stop_words]\n",
    "                )\n",
    "                top_words = word_counts.most_common(5)\n",
    "\n",
    "                # Add high-frequency words as patterns\n",
    "                for word, count in top_words:\n",
    "                    if count >= 2:  # Only if appears in multiple examples\n",
    "                        pattern = f\"\\\\b{re.escape(word)}\\\\b\"\n",
    "                        if pattern not in self.rules[category]:\n",
    "                            self.rules[category].append(pattern)\n",
    "\n",
    "\n",
    "# Initialize rule extractor\n",
    "rule_extractor = RuleExtractor()\n",
    "print(\"🤖 Rule Extractor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e92e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Retrieving manual annotations...\n",
      "❌ Failed to retrieve annotations: 404\n",
      "⚠️  No annotations found. Please label some data in Label Studio first.\n",
      "   Go to: http://localhost:8080/projects/None\n",
      "\n",
      "🔧 Using default rule patterns...\n"
     ]
    }
   ],
   "source": [
    "# Extract rules from manual annotations\n",
    "print(\"📥 Retrieving manual annotations...\")\n",
    "\n",
    "# Note: Make sure you have labeled some data in Label Studio before running this\n",
    "try:\n",
    "    annotations = ls_manager.get_annotations(project_id)\n",
    "\n",
    "    if len(annotations) > 0:\n",
    "        print(f\"\\n🔍 Extracting labeling rules from {len(annotations)} annotations...\")\n",
    "        extracted_rules = rule_extractor.extract_rules_from_annotations(annotations)\n",
    "\n",
    "        print(f\"\\n📋 Final Rules Summary:\")\n",
    "        for category, patterns in extracted_rules.items():\n",
    "            print(f\"\\n   🎯 {category} ({len(patterns)} rules):\")\n",
    "            for i, pattern in enumerate(patterns[:5], 1):  # Show first 5 rules\n",
    "                print(f\"      {i}. {pattern}\")\n",
    "            if len(patterns) > 5:\n",
    "                print(f\"      ... and {len(patterns) - 5} more\")\n",
    "\n",
    "        print(f\"\\n✅ Rules extracted successfully!\")\n",
    "        print(f\"📊 Ready to apply to full dataset ({len(df_full):,} rows)\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️  No annotations found. Please label some data in Label Studio first.\")\n",
    "        print(f\"   Go to: {LABEL_STUDIO_URL}/projects/{project_id}\")\n",
    "\n",
    "        # Use default rules if no annotations\n",
    "        print(\"\\n🔧 Using default rule patterns...\")\n",
    "        extracted_rules = rule_extractor.rules\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error retrieving annotations: {e}\")\n",
    "    # Use default rules\n",
    "    extracted_rules = rule_extractor.rules\n",
    "    print(\"🔧 Using default rule patterns...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdd74a",
   "metadata": {},
   "source": [
    "## ⚡ 6. Auto-Label Full Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000fa970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Compiled 0 regex patterns\n",
      "⚡ Auto-labeler initialized with extracted rules\n"
     ]
    }
   ],
   "source": [
    "class AutoLabeler:\n",
    "    \"\"\"Apply extracted rules to automatically label the full dataset\"\"\"\n",
    "\n",
    "    def __init__(self, rules: Dict[str, List[str]]):\n",
    "        self.rules = rules\n",
    "        self.compiled_patterns = {}\n",
    "        self._compile_patterns()\n",
    "\n",
    "    def _compile_patterns(self):\n",
    "        \"\"\"Compile regex patterns for better performance\"\"\"\n",
    "        for category, patterns in self.rules.items():\n",
    "            compiled = []\n",
    "            for pattern in patterns:\n",
    "                try:\n",
    "                    compiled.append(re.compile(pattern, re.IGNORECASE))\n",
    "                except re.error:\n",
    "                    print(f\"⚠️  Invalid regex pattern skipped: {pattern}\")\n",
    "            self.compiled_patterns[category] = compiled\n",
    "\n",
    "        print(\n",
    "            f\"✅ Compiled {sum(len(p) for p in self.compiled_patterns.values())} regex patterns\"\n",
    "        )\n",
    "\n",
    "    def label_text(self, text: str) -> Dict[str, bool]:\n",
    "        \"\"\"Apply rules to label a single text\"\"\"\n",
    "        labels = {\"Advertisement\": False, \"Irrelevant\": False, \"Fake_Rant\": False}\n",
    "\n",
    "        if pd.isna(text) or text == \"\":\n",
    "            return labels\n",
    "\n",
    "        text_lower = str(text).lower()\n",
    "\n",
    "        for category, patterns in self.compiled_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if pattern.search(text_lower):\n",
    "                    labels[category] = True\n",
    "                    break  # One match is enough for this category\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def label_dataframe(\n",
    "        self, df: pd.DataFrame, text_column: str = \"review_text\"\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Apply auto-labeling to entire dataframe\"\"\"\n",
    "        print(f\"🚀 Starting auto-labeling on {len(df):,} rows...\")\n",
    "\n",
    "        # Initialize result columns\n",
    "        df_labeled = df.copy()\n",
    "        df_labeled[\"advertisement\"] = False\n",
    "        df_labeled[\"irrelevant\"] = False\n",
    "        df_labeled[\"fake_rant\"] = False\n",
    "\n",
    "        # Apply labeling rules\n",
    "        batch_size = 1000\n",
    "        total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch_end = min(i + batch_size, len(df))\n",
    "            batch_num = i // batch_size + 1\n",
    "\n",
    "            print(\n",
    "                f\"   Processing batch {batch_num}/{total_batches} ({i+1}-{batch_end})...\"\n",
    "            )\n",
    "\n",
    "            for idx in range(i, batch_end):\n",
    "                text = df.iloc[idx][text_column]\n",
    "                labels = self.label_text(text)\n",
    "\n",
    "                df_labeled.iloc[idx, df_labeled.columns.get_loc(\"advertisement\")] = (\n",
    "                    labels[\"Advertisement\"]\n",
    "                )\n",
    "                df_labeled.iloc[idx, df_labeled.columns.get_loc(\"irrelevant\")] = labels[\n",
    "                    \"Irrelevant\"\n",
    "                ]\n",
    "                df_labeled.iloc[idx, df_labeled.columns.get_loc(\"fake_rant\")] = labels[\n",
    "                    \"Fake_Rant\"\n",
    "                ]\n",
    "\n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            \"advertisement\": df_labeled[\"advertisement\"].sum(),\n",
    "            \"irrelevant\": df_labeled[\"irrelevant\"].sum(),\n",
    "            \"fake_rant\": df_labeled[\"fake_rant\"].sum(),\n",
    "        }\n",
    "\n",
    "        print(f\"\\n✅ Auto-labeling completed!\")\n",
    "        print(f\"\\n📊 Labeling Results:\")\n",
    "        for label, count in stats.items():\n",
    "            percentage = (count / len(df_labeled)) * 100\n",
    "            print(f\"   {label}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "        return df_labeled\n",
    "\n",
    "\n",
    "# Initialize auto-labeler\n",
    "auto_labeler = AutoLabeler(extracted_rules)\n",
    "print(\"⚡ Auto-labeler initialized with extracted rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aad5215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Applying auto-labeling to full dataset...\n",
      "📊 Dataset size: 347,087 rows\n",
      "🚀 Starting auto-labeling on 347,087 rows...\n",
      "   Processing batch 1/348 (1-1000)...\n",
      "   Processing batch 2/348 (1001-2000)...\n",
      "   Processing batch 3/348 (2001-3000)...\n",
      "   Processing batch 4/348 (3001-4000)...\n",
      "   Processing batch 5/348 (4001-5000)...\n",
      "   Processing batch 6/348 (5001-6000)...\n",
      "   Processing batch 7/348 (6001-7000)...\n",
      "   Processing batch 8/348 (7001-8000)...\n",
      "   Processing batch 9/348 (8001-9000)...\n",
      "   Processing batch 10/348 (9001-10000)...\n",
      "   Processing batch 11/348 (10001-11000)...\n",
      "   Processing batch 12/348 (11001-12000)...\n",
      "   Processing batch 13/348 (12001-13000)...\n",
      "   Processing batch 14/348 (13001-14000)...\n",
      "   Processing batch 15/348 (14001-15000)...\n",
      "   Processing batch 16/348 (15001-16000)...\n",
      "   Processing batch 17/348 (16001-17000)...\n",
      "   Processing batch 18/348 (17001-18000)...\n",
      "   Processing batch 19/348 (18001-19000)...\n",
      "   Processing batch 20/348 (19001-20000)...\n",
      "   Processing batch 21/348 (20001-21000)...\n",
      "   Processing batch 22/348 (21001-22000)...\n",
      "   Processing batch 23/348 (22001-23000)...\n",
      "   Processing batch 24/348 (23001-24000)...\n",
      "   Processing batch 25/348 (24001-25000)...\n",
      "   Processing batch 26/348 (25001-26000)...\n",
      "   Processing batch 27/348 (26001-27000)...\n",
      "   Processing batch 28/348 (27001-28000)...\n",
      "   Processing batch 29/348 (28001-29000)...\n",
      "   Processing batch 30/348 (29001-30000)...\n",
      "   Processing batch 31/348 (30001-31000)...\n",
      "   Processing batch 32/348 (31001-32000)...\n",
      "   Processing batch 33/348 (32001-33000)...\n",
      "   Processing batch 34/348 (33001-34000)...\n",
      "   Processing batch 35/348 (34001-35000)...\n",
      "   Processing batch 36/348 (35001-36000)...\n",
      "   Processing batch 37/348 (36001-37000)...\n",
      "   Processing batch 38/348 (37001-38000)...\n",
      "   Processing batch 39/348 (38001-39000)...\n",
      "   Processing batch 40/348 (39001-40000)...\n",
      "   Processing batch 41/348 (40001-41000)...\n",
      "   Processing batch 42/348 (41001-42000)...\n",
      "   Processing batch 43/348 (42001-43000)...\n",
      "   Processing batch 44/348 (43001-44000)...\n",
      "   Processing batch 45/348 (44001-45000)...\n",
      "   Processing batch 46/348 (45001-46000)...\n",
      "   Processing batch 47/348 (46001-47000)...\n",
      "   Processing batch 48/348 (47001-48000)...\n",
      "   Processing batch 49/348 (48001-49000)...\n",
      "   Processing batch 50/348 (49001-50000)...\n",
      "   Processing batch 51/348 (50001-51000)...\n",
      "   Processing batch 52/348 (51001-52000)...\n",
      "   Processing batch 53/348 (52001-53000)...\n",
      "   Processing batch 54/348 (53001-54000)...\n",
      "   Processing batch 55/348 (54001-55000)...\n",
      "   Processing batch 56/348 (55001-56000)...\n",
      "   Processing batch 57/348 (56001-57000)...\n",
      "   Processing batch 58/348 (57001-58000)...\n",
      "   Processing batch 59/348 (58001-59000)...\n",
      "   Processing batch 60/348 (59001-60000)...\n",
      "   Processing batch 61/348 (60001-61000)...\n",
      "   Processing batch 62/348 (61001-62000)...\n",
      "   Processing batch 63/348 (62001-63000)...\n",
      "   Processing batch 64/348 (63001-64000)...\n",
      "   Processing batch 65/348 (64001-65000)...\n",
      "   Processing batch 66/348 (65001-66000)...\n",
      "   Processing batch 67/348 (66001-67000)...\n",
      "   Processing batch 68/348 (67001-68000)...\n",
      "   Processing batch 69/348 (68001-69000)...\n",
      "   Processing batch 70/348 (69001-70000)...\n",
      "   Processing batch 71/348 (70001-71000)...\n",
      "   Processing batch 72/348 (71001-72000)...\n",
      "   Processing batch 73/348 (72001-73000)...\n",
      "   Processing batch 74/348 (73001-74000)...\n",
      "   Processing batch 75/348 (74001-75000)...\n",
      "   Processing batch 76/348 (75001-76000)...\n",
      "   Processing batch 77/348 (76001-77000)...\n",
      "   Processing batch 78/348 (77001-78000)...\n",
      "   Processing batch 79/348 (78001-79000)...\n",
      "   Processing batch 80/348 (79001-80000)...\n",
      "   Processing batch 81/348 (80001-81000)...\n",
      "   Processing batch 82/348 (81001-82000)...\n",
      "   Processing batch 83/348 (82001-83000)...\n",
      "   Processing batch 84/348 (83001-84000)...\n",
      "   Processing batch 85/348 (84001-85000)...\n",
      "   Processing batch 86/348 (85001-86000)...\n",
      "   Processing batch 87/348 (86001-87000)...\n",
      "   Processing batch 88/348 (87001-88000)...\n",
      "   Processing batch 89/348 (88001-89000)...\n",
      "   Processing batch 90/348 (89001-90000)...\n",
      "   Processing batch 91/348 (90001-91000)...\n",
      "   Processing batch 92/348 (91001-92000)...\n",
      "   Processing batch 93/348 (92001-93000)...\n",
      "   Processing batch 94/348 (93001-94000)...\n",
      "   Processing batch 95/348 (94001-95000)...\n",
      "   Processing batch 96/348 (95001-96000)...\n",
      "   Processing batch 97/348 (96001-97000)...\n",
      "   Processing batch 98/348 (97001-98000)...\n",
      "   Processing batch 99/348 (98001-99000)...\n",
      "   Processing batch 100/348 (99001-100000)...\n",
      "   Processing batch 101/348 (100001-101000)...\n",
      "   Processing batch 102/348 (101001-102000)...\n",
      "   Processing batch 103/348 (102001-103000)...\n",
      "   Processing batch 104/348 (103001-104000)...\n",
      "   Processing batch 105/348 (104001-105000)...\n",
      "   Processing batch 106/348 (105001-106000)...\n",
      "   Processing batch 107/348 (106001-107000)...\n",
      "   Processing batch 108/348 (107001-108000)...\n",
      "   Processing batch 109/348 (108001-109000)...\n",
      "   Processing batch 110/348 (109001-110000)...\n",
      "   Processing batch 111/348 (110001-111000)...\n",
      "   Processing batch 112/348 (111001-112000)...\n",
      "   Processing batch 113/348 (112001-113000)...\n",
      "   Processing batch 114/348 (113001-114000)...\n",
      "   Processing batch 115/348 (114001-115000)...\n",
      "   Processing batch 116/348 (115001-116000)...\n",
      "   Processing batch 117/348 (116001-117000)...\n",
      "   Processing batch 118/348 (117001-118000)...\n",
      "   Processing batch 119/348 (118001-119000)...\n",
      "   Processing batch 120/348 (119001-120000)...\n",
      "   Processing batch 121/348 (120001-121000)...\n",
      "   Processing batch 122/348 (121001-122000)...\n",
      "   Processing batch 123/348 (122001-123000)...\n",
      "   Processing batch 124/348 (123001-124000)...\n",
      "   Processing batch 125/348 (124001-125000)...\n",
      "   Processing batch 126/348 (125001-126000)...\n",
      "   Processing batch 127/348 (126001-127000)...\n",
      "   Processing batch 128/348 (127001-128000)...\n",
      "   Processing batch 129/348 (128001-129000)...\n",
      "   Processing batch 130/348 (129001-130000)...\n",
      "   Processing batch 131/348 (130001-131000)...\n",
      "   Processing batch 132/348 (131001-132000)...\n",
      "   Processing batch 133/348 (132001-133000)...\n",
      "   Processing batch 134/348 (133001-134000)...\n",
      "   Processing batch 135/348 (134001-135000)...\n",
      "   Processing batch 136/348 (135001-136000)...\n",
      "   Processing batch 137/348 (136001-137000)...\n",
      "   Processing batch 138/348 (137001-138000)...\n",
      "   Processing batch 139/348 (138001-139000)...\n",
      "   Processing batch 140/348 (139001-140000)...\n",
      "   Processing batch 141/348 (140001-141000)...\n",
      "   Processing batch 142/348 (141001-142000)...\n",
      "   Processing batch 143/348 (142001-143000)...\n",
      "   Processing batch 144/348 (143001-144000)...\n",
      "   Processing batch 145/348 (144001-145000)...\n",
      "   Processing batch 146/348 (145001-146000)...\n",
      "   Processing batch 147/348 (146001-147000)...\n",
      "   Processing batch 148/348 (147001-148000)...\n",
      "   Processing batch 149/348 (148001-149000)...\n",
      "   Processing batch 150/348 (149001-150000)...\n",
      "   Processing batch 151/348 (150001-151000)...\n",
      "   Processing batch 152/348 (151001-152000)...\n",
      "   Processing batch 153/348 (152001-153000)...\n",
      "   Processing batch 154/348 (153001-154000)...\n",
      "   Processing batch 155/348 (154001-155000)...\n",
      "   Processing batch 156/348 (155001-156000)...\n",
      "   Processing batch 157/348 (156001-157000)...\n",
      "   Processing batch 158/348 (157001-158000)...\n",
      "   Processing batch 159/348 (158001-159000)...\n",
      "   Processing batch 160/348 (159001-160000)...\n",
      "   Processing batch 161/348 (160001-161000)...\n",
      "   Processing batch 162/348 (161001-162000)...\n",
      "   Processing batch 163/348 (162001-163000)...\n",
      "   Processing batch 164/348 (163001-164000)...\n",
      "   Processing batch 165/348 (164001-165000)...\n",
      "   Processing batch 166/348 (165001-166000)...\n",
      "   Processing batch 167/348 (166001-167000)...\n",
      "   Processing batch 168/348 (167001-168000)...\n",
      "   Processing batch 169/348 (168001-169000)...\n",
      "   Processing batch 170/348 (169001-170000)...\n",
      "   Processing batch 171/348 (170001-171000)...\n",
      "   Processing batch 172/348 (171001-172000)...\n",
      "   Processing batch 173/348 (172001-173000)...\n",
      "   Processing batch 174/348 (173001-174000)...\n",
      "   Processing batch 175/348 (174001-175000)...\n",
      "   Processing batch 176/348 (175001-176000)...\n",
      "   Processing batch 177/348 (176001-177000)...\n",
      "   Processing batch 178/348 (177001-178000)...\n",
      "   Processing batch 179/348 (178001-179000)...\n",
      "   Processing batch 180/348 (179001-180000)...\n",
      "   Processing batch 181/348 (180001-181000)...\n",
      "   Processing batch 182/348 (181001-182000)...\n",
      "   Processing batch 183/348 (182001-183000)...\n",
      "   Processing batch 184/348 (183001-184000)...\n",
      "   Processing batch 185/348 (184001-185000)...\n",
      "   Processing batch 186/348 (185001-186000)...\n",
      "   Processing batch 187/348 (186001-187000)...\n",
      "   Processing batch 188/348 (187001-188000)...\n",
      "   Processing batch 189/348 (188001-189000)...\n",
      "   Processing batch 190/348 (189001-190000)...\n",
      "   Processing batch 191/348 (190001-191000)...\n",
      "   Processing batch 192/348 (191001-192000)...\n",
      "   Processing batch 193/348 (192001-193000)...\n",
      "   Processing batch 194/348 (193001-194000)...\n",
      "   Processing batch 195/348 (194001-195000)...\n",
      "   Processing batch 196/348 (195001-196000)...\n",
      "   Processing batch 197/348 (196001-197000)...\n",
      "   Processing batch 198/348 (197001-198000)...\n",
      "   Processing batch 199/348 (198001-199000)...\n",
      "   Processing batch 200/348 (199001-200000)...\n",
      "   Processing batch 201/348 (200001-201000)...\n",
      "   Processing batch 202/348 (201001-202000)...\n",
      "   Processing batch 203/348 (202001-203000)...\n",
      "   Processing batch 204/348 (203001-204000)...\n",
      "   Processing batch 205/348 (204001-205000)...\n",
      "   Processing batch 206/348 (205001-206000)...\n",
      "   Processing batch 207/348 (206001-207000)...\n",
      "   Processing batch 208/348 (207001-208000)...\n",
      "   Processing batch 209/348 (208001-209000)...\n",
      "   Processing batch 210/348 (209001-210000)...\n",
      "   Processing batch 211/348 (210001-211000)...\n",
      "   Processing batch 212/348 (211001-212000)...\n",
      "   Processing batch 213/348 (212001-213000)...\n",
      "   Processing batch 214/348 (213001-214000)...\n",
      "   Processing batch 215/348 (214001-215000)...\n",
      "   Processing batch 216/348 (215001-216000)...\n",
      "   Processing batch 217/348 (216001-217000)...\n",
      "   Processing batch 218/348 (217001-218000)...\n",
      "   Processing batch 219/348 (218001-219000)...\n",
      "   Processing batch 220/348 (219001-220000)...\n",
      "   Processing batch 221/348 (220001-221000)...\n",
      "   Processing batch 222/348 (221001-222000)...\n",
      "   Processing batch 223/348 (222001-223000)...\n",
      "   Processing batch 224/348 (223001-224000)...\n",
      "   Processing batch 225/348 (224001-225000)...\n",
      "   Processing batch 226/348 (225001-226000)...\n",
      "   Processing batch 227/348 (226001-227000)...\n",
      "   Processing batch 228/348 (227001-228000)...\n",
      "   Processing batch 229/348 (228001-229000)...\n",
      "   Processing batch 230/348 (229001-230000)...\n",
      "   Processing batch 231/348 (230001-231000)...\n",
      "   Processing batch 232/348 (231001-232000)...\n",
      "   Processing batch 233/348 (232001-233000)...\n",
      "   Processing batch 234/348 (233001-234000)...\n",
      "   Processing batch 235/348 (234001-235000)...\n",
      "   Processing batch 236/348 (235001-236000)...\n",
      "   Processing batch 237/348 (236001-237000)...\n",
      "   Processing batch 238/348 (237001-238000)...\n",
      "   Processing batch 239/348 (238001-239000)...\n",
      "   Processing batch 240/348 (239001-240000)...\n",
      "   Processing batch 241/348 (240001-241000)...\n",
      "   Processing batch 242/348 (241001-242000)...\n",
      "   Processing batch 243/348 (242001-243000)...\n",
      "   Processing batch 244/348 (243001-244000)...\n",
      "   Processing batch 245/348 (244001-245000)...\n",
      "   Processing batch 246/348 (245001-246000)...\n",
      "   Processing batch 247/348 (246001-247000)...\n",
      "   Processing batch 248/348 (247001-248000)...\n",
      "   Processing batch 249/348 (248001-249000)...\n",
      "   Processing batch 250/348 (249001-250000)...\n",
      "   Processing batch 251/348 (250001-251000)...\n",
      "   Processing batch 252/348 (251001-252000)...\n",
      "   Processing batch 253/348 (252001-253000)...\n",
      "   Processing batch 254/348 (253001-254000)...\n",
      "   Processing batch 255/348 (254001-255000)...\n",
      "   Processing batch 256/348 (255001-256000)...\n",
      "   Processing batch 257/348 (256001-257000)...\n",
      "   Processing batch 258/348 (257001-258000)...\n",
      "   Processing batch 259/348 (258001-259000)...\n",
      "   Processing batch 260/348 (259001-260000)...\n",
      "   Processing batch 261/348 (260001-261000)...\n",
      "   Processing batch 262/348 (261001-262000)...\n",
      "   Processing batch 263/348 (262001-263000)...\n",
      "   Processing batch 264/348 (263001-264000)...\n",
      "   Processing batch 265/348 (264001-265000)...\n",
      "   Processing batch 266/348 (265001-266000)...\n",
      "   Processing batch 267/348 (266001-267000)...\n",
      "   Processing batch 268/348 (267001-268000)...\n",
      "   Processing batch 269/348 (268001-269000)...\n",
      "   Processing batch 270/348 (269001-270000)...\n",
      "   Processing batch 271/348 (270001-271000)...\n",
      "   Processing batch 272/348 (271001-272000)...\n",
      "   Processing batch 273/348 (272001-273000)...\n",
      "   Processing batch 274/348 (273001-274000)...\n",
      "   Processing batch 275/348 (274001-275000)...\n",
      "   Processing batch 276/348 (275001-276000)...\n",
      "   Processing batch 277/348 (276001-277000)...\n",
      "   Processing batch 278/348 (277001-278000)...\n",
      "   Processing batch 279/348 (278001-279000)...\n",
      "   Processing batch 280/348 (279001-280000)...\n",
      "   Processing batch 281/348 (280001-281000)...\n",
      "   Processing batch 282/348 (281001-282000)...\n",
      "   Processing batch 283/348 (282001-283000)...\n",
      "   Processing batch 284/348 (283001-284000)...\n",
      "   Processing batch 285/348 (284001-285000)...\n",
      "   Processing batch 286/348 (285001-286000)...\n",
      "   Processing batch 287/348 (286001-287000)...\n",
      "   Processing batch 288/348 (287001-288000)...\n",
      "   Processing batch 289/348 (288001-289000)...\n",
      "   Processing batch 290/348 (289001-290000)...\n",
      "   Processing batch 291/348 (290001-291000)...\n",
      "   Processing batch 292/348 (291001-292000)...\n",
      "   Processing batch 293/348 (292001-293000)...\n",
      "   Processing batch 294/348 (293001-294000)...\n",
      "   Processing batch 295/348 (294001-295000)...\n",
      "   Processing batch 296/348 (295001-296000)...\n",
      "   Processing batch 297/348 (296001-297000)...\n",
      "   Processing batch 298/348 (297001-298000)...\n",
      "   Processing batch 299/348 (298001-299000)...\n",
      "   Processing batch 300/348 (299001-300000)...\n",
      "   Processing batch 301/348 (300001-301000)...\n",
      "   Processing batch 302/348 (301001-302000)...\n",
      "   Processing batch 303/348 (302001-303000)...\n",
      "   Processing batch 304/348 (303001-304000)...\n",
      "   Processing batch 305/348 (304001-305000)...\n",
      "   Processing batch 306/348 (305001-306000)...\n",
      "   Processing batch 307/348 (306001-307000)...\n",
      "   Processing batch 308/348 (307001-308000)...\n",
      "   Processing batch 309/348 (308001-309000)...\n",
      "   Processing batch 310/348 (309001-310000)...\n",
      "   Processing batch 311/348 (310001-311000)...\n",
      "   Processing batch 312/348 (311001-312000)...\n",
      "   Processing batch 313/348 (312001-313000)...\n",
      "   Processing batch 314/348 (313001-314000)...\n",
      "   Processing batch 315/348 (314001-315000)...\n",
      "   Processing batch 316/348 (315001-316000)...\n",
      "   Processing batch 317/348 (316001-317000)...\n",
      "   Processing batch 318/348 (317001-318000)...\n",
      "   Processing batch 319/348 (318001-319000)...\n",
      "   Processing batch 320/348 (319001-320000)...\n",
      "   Processing batch 321/348 (320001-321000)...\n",
      "   Processing batch 322/348 (321001-322000)...\n",
      "   Processing batch 323/348 (322001-323000)...\n",
      "   Processing batch 324/348 (323001-324000)...\n",
      "   Processing batch 325/348 (324001-325000)...\n",
      "   Processing batch 326/348 (325001-326000)...\n",
      "   Processing batch 327/348 (326001-327000)...\n",
      "   Processing batch 328/348 (327001-328000)...\n",
      "   Processing batch 329/348 (328001-329000)...\n",
      "   Processing batch 330/348 (329001-330000)...\n",
      "   Processing batch 331/348 (330001-331000)...\n",
      "   Processing batch 332/348 (331001-332000)...\n",
      "   Processing batch 333/348 (332001-333000)...\n",
      "   Processing batch 334/348 (333001-334000)...\n",
      "   Processing batch 335/348 (334001-335000)...\n",
      "   Processing batch 336/348 (335001-336000)...\n",
      "   Processing batch 337/348 (336001-337000)...\n",
      "   Processing batch 338/348 (337001-338000)...\n",
      "   Processing batch 339/348 (338001-339000)...\n",
      "   Processing batch 340/348 (339001-340000)...\n",
      "   Processing batch 341/348 (340001-341000)...\n",
      "   Processing batch 342/348 (341001-342000)...\n",
      "   Processing batch 343/348 (342001-343000)...\n",
      "   Processing batch 344/348 (343001-344000)...\n",
      "   Processing batch 345/348 (344001-345000)...\n",
      "   Processing batch 346/348 (345001-346000)...\n",
      "   Processing batch 347/348 (346001-347000)...\n",
      "   Processing batch 348/348 (347001-347087)...\n",
      "\n",
      "✅ Auto-labeling completed!\n",
      "\n",
      "📊 Labeling Results:\n",
      "   advertisement: 0 (0.0%)\n",
      "   irrelevant: 0 (0.0%)\n",
      "   fake_rant: 0 (0.0%)\n",
      "\n",
      "🎉 Auto-labeling pipeline completed!\n",
      "\n",
      "📋 Sample Auto-Labeled Results:\n",
      "\n",
      "   Row 0:\n",
      "   📝 Review: 'Great place to care for our children....'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 1:\n",
      "   📝 Review: 'Th sw y are so nice...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 2:\n",
      "   📝 Review: 'Went with my daughter...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 3:\n",
      "   📝 Review: 'Julie and the crew are AMAZING. DONATE DONATE DONATE. this is one of the MOST wo...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 4:\n",
      "   📝 Review: 'They dont have any activities for youth. If so, they don't promote it well.  No ...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 5:\n",
      "   📝 Review: 'So much done for the youth and community here!...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 6:\n",
      "   📝 Review: 'Amazing work done here!...'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 7:\n",
      "   📝 Review: 'Great place for the children....'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 8:\n",
      "   📝 Review: 'Doing wonderful work....'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "   Row 9:\n",
      "   📝 Review: 'Helpful, and good service....'\n",
      "   🏷️  Labels: Clean\n",
      "\n",
      "📈 Final Statistics:\n",
      "   Total rows processed: 347,087\n",
      "   Rows with violations: 0 (0.0%)\n",
      "   Clean rows: 347,087 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Apply auto-labeling to full dataset\n",
    "print(f\"🎯 Applying auto-labeling to full dataset...\")\n",
    "print(f\"📊 Dataset size: {len(df_full):,} rows\")\n",
    "\n",
    "# Apply auto-labeling\n",
    "df_auto_labeled = auto_labeler.label_dataframe(df_full, \"review_text\")\n",
    "\n",
    "print(f\"\\n🎉 Auto-labeling pipeline completed!\")\n",
    "\n",
    "# Display sample results\n",
    "print(f\"\\n📋 Sample Auto-Labeled Results:\")\n",
    "sample_results = df_auto_labeled[\n",
    "    [\"review_text\", \"advertisement\", \"irrelevant\", \"fake_rant\"]\n",
    "].head(10)\n",
    "\n",
    "for idx, row in sample_results.iterrows():\n",
    "    labels = []\n",
    "    if row[\"advertisement\"]:\n",
    "        labels.append(\"Advertisement\")\n",
    "    if row[\"irrelevant\"]:\n",
    "        labels.append(\"Irrelevant\")\n",
    "    if row[\"fake_rant\"]:\n",
    "        labels.append(\"Fake_Rant\")\n",
    "\n",
    "    label_str = \", \".join(labels) if labels else \"Clean\"\n",
    "\n",
    "    print(f\"\\n   Row {idx}:\")\n",
    "    print(f\"   📝 Review: '{row['review_text'][:80]}...'\")\n",
    "    print(f\"   🏷️  Labels: {label_str}\")\n",
    "\n",
    "# Calculate final statistics\n",
    "total_rows = len(df_auto_labeled)\n",
    "labeled_rows = (\n",
    "    df_auto_labeled[[\"advertisement\", \"irrelevant\", \"fake_rant\"]].any(axis=1).sum()\n",
    ")\n",
    "clean_rows = total_rows - labeled_rows\n",
    "\n",
    "print(f\"\\n📈 Final Statistics:\")\n",
    "print(f\"   Total rows processed: {total_rows:,}\")\n",
    "print(f\"   Rows with violations: {labeled_rows:,} ({labeled_rows/total_rows*100:.1f}%)\")\n",
    "print(f\"   Clean rows: {clean_rows:,} ({clean_rows/total_rows*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602054a1",
   "metadata": {},
   "source": [
    "## 💾 7. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1eec2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Auto-labeled dataset saved:\n",
      "   📁 Path: ../outputs/auto_labeled/auto_labeled_reviews_20250829_153319.csv\n",
      "   📊 Size: 347,087 rows\n",
      "   🏷️  Columns: ['user_id', 'user_name', 'review_time', 'rating', 'review_text', 'pics', 'resp', 'gmap_id', 'has_resp', 'resp_text', 'resp_time', 'biz_name', 'description', 'category', 'avg_rating', 'num_of_reviews', 'price_level', 'advertisement', 'irrelevant', 'fake_rant']\n",
      "\n",
      "📋 Labeling rules saved:\n",
      "   📁 Path: ../outputs/auto_labeled/labeling_rules_20250829_153319.json\n",
      "\n",
      "📊 Summary report saved: ../outputs/auto_labeled/summary_20250829_153319.json\n",
      "\n",
      "🎉 AUTO-LABELING PIPELINE COMPLETE!\n",
      "\n",
      "📋 Workflow Summary:\n",
      "   1. ✅ Loaded 347,087 reviews from ../data/cleaned_google_reviews.csv\n",
      "   2. ✅ Sampled 34,708 rows (10.0%) for manual labeling\n",
      "   3. ✅ Sent sample to Label Studio for manual labeling\n",
      "   4. ✅ Extracted 0 labeling rules\n",
      "   5. ✅ Applied rules to auto-label 347,087 rows\n",
      "   6. ✅ Saved results to ../outputs/auto_labeled\n",
      "\n",
      "🚀 Ready for ML model training with labeled data!\n"
     ]
    }
   ],
   "source": [
    "# Save auto-labeled dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"../outputs/auto_labeled\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"auto_labeled_reviews_{timestamp}.csv\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# Save the labeled dataset\n",
    "df_auto_labeled.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"💾 Auto-labeled dataset saved:\")\n",
    "print(f\"   📁 Path: {output_path}\")\n",
    "print(f\"   📊 Size: {len(df_auto_labeled):,} rows\")\n",
    "print(f\"   🏷️  Columns: {df_auto_labeled.columns.tolist()}\")\n",
    "\n",
    "# Save rules for future use\n",
    "rules_filename = f\"labeling_rules_{timestamp}.json\"\n",
    "rules_path = os.path.join(output_dir, rules_filename)\n",
    "\n",
    "with open(rules_path, \"w\") as f:\n",
    "    json.dump(extracted_rules, f, indent=2)\n",
    "\n",
    "print(f\"\\n📋 Labeling rules saved:\")\n",
    "print(f\"   📁 Path: {rules_path}\")\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"original_dataset\": DATA_PATH,\n",
    "    \"total_rows_processed\": len(df_auto_labeled),\n",
    "    \"sample_size_for_manual_labeling\": len(df_sample),\n",
    "    \"sample_percentage\": SAMPLE_PERCENTAGE,\n",
    "    \"label_statistics\": {\n",
    "        \"advertisement\": int(df_auto_labeled[\"advertisement\"].sum()),\n",
    "        \"irrelevant\": int(df_auto_labeled[\"irrelevant\"].sum()),\n",
    "        \"fake_rant\": int(df_auto_labeled[\"fake_rant\"].sum()),\n",
    "        \"clean\": int(\n",
    "            (\n",
    "                ~df_auto_labeled[[\"advertisement\", \"irrelevant\", \"fake_rant\"]].any(\n",
    "                    axis=1\n",
    "                )\n",
    "            ).sum()\n",
    "        ),\n",
    "    },\n",
    "    \"rules_count\": {\n",
    "        category: len(patterns) for category, patterns in extracted_rules.items()\n",
    "    },\n",
    "    \"output_files\": {\"labeled_data\": output_path, \"rules\": rules_path},\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(output_dir, f\"summary_{timestamp}.json\")\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n📊 Summary report saved: {summary_path}\")\n",
    "\n",
    "print(f\"\\n🎉 AUTO-LABELING PIPELINE COMPLETE!\")\n",
    "print(f\"\\n📋 Workflow Summary:\")\n",
    "print(f\"   1. ✅ Loaded {len(df_full):,} reviews from {DATA_PATH}\")\n",
    "print(\n",
    "    f\"   2. ✅ Sampled {len(df_sample):,} rows ({SAMPLE_PERCENTAGE*100}%) for manual labeling\"\n",
    ")\n",
    "print(f\"   3. ✅ Sent sample to Label Studio for manual labeling\")\n",
    "print(\n",
    "    f\"   4. ✅ Extracted {sum(len(p) for p in extracted_rules.values())} labeling rules\"\n",
    ")\n",
    "print(f\"   5. ✅ Applied rules to auto-label {len(df_auto_labeled):,} rows\")\n",
    "print(f\"   6. ✅ Saved results to {output_dir}\")\n",
    "\n",
    "print(f\"\\n🚀 Ready for ML model training with labeled data!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
